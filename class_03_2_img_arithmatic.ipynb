{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> 👉 class_03_2 IP » _Arithmetic Operations - Synthesizing, Blending, Masking & Reversing_ </center>\n",
    "\n",
    "# ▣ Arithmetic Operations on Images  \n",
    "\n",
    "Learn several arithmetic operations on images like addition, subtraction, bitwise operations etc.  \n",
    "You will learn these functions : \n",
    "* **cv2.add()**  \n",
    "* **cv2.addWeighted()** etc.  \n",
    "\n",
    "## ▶ Image Addition  \n",
    "You can add two images by OpenCV function, cv2.add() or simply by numpy operation,   \n",
    "- res = img1 + img2.  \n",
    "\n",
    "Both images should be of same depth and type, or second image can just be a scalar value.  \n",
    "\n",
    "~ Syntax:  \n",
    "    \n",
    "* **cv2.add(src1, src2, dst, mask, dtype):** \n",
    "\n",
    "~ Parameters:    \n",
    "* src1: 1st img\n",
    "* src2: 2nd img\n",
    "* dst(optional): output img\n",
    "* mask(optional): Computes only non-zero pixels with mask values\n",
    "* dtype(optional): output data type (dtype)\n",
    "\n",
    "### Note\n",
    "\n",
    "There is a difference between OpenCV addition and Numpy addition.  \n",
    "OpenCV addition is a saturated operation while Numpy addition is a modulo operation.\n",
    "\n",
    "For example, consider below sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "x = np.uint8([250])\n",
    "y = np.uint8([10])\n",
    "print('Numpy add x+y = ', x+y ) # 250+10 = 260 % 256 = 4\n",
    "print('cv.add(x,y) = ', cv2.add(x,y) ) # 250+10 = 260 => 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be more visible when you add two images.  \n",
    "OpenCV function will provide a better result.  \n",
    "So always better stick to OpenCV functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▶ Image Subtraction \n",
    "\n",
    "~ Syntax:  \n",
    "    \n",
    "* **cv2.subtract(src1, src2, dst, mask, dtype):** \n",
    "\n",
    "~ Parameters: same as the cv2.add() \n",
    "\n",
    "## ▶ Image Multiply   \n",
    "\n",
    "~ Syntax:  \n",
    "    \n",
    "* **cv2.multiply(src1, src2, dst, scale, dtype):** \n",
    "\n",
    "~ Parameters:  \n",
    "    \n",
    "* scale(optional): multiple value  \n",
    "\n",
    "## ▶ Image Divide  \n",
    "\n",
    "~ Syntax:  \n",
    "    \n",
    "* **cv2.divide(src1, src2, dst, scale, dtype):** \n",
    "\n",
    "~ Parameters: same as the cv2.multiply()\n",
    "\n",
    "## ▶ Examples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arithmatic.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a = np.uint8([[200, 50]]) \n",
    "b = np.uint8([[100, 100]])\n",
    "\n",
    "add1 = a + b  # NumPy operation\n",
    "sub1 = a - b\n",
    "mult1 = a * 2\n",
    "div1 = a / 3\n",
    "\n",
    "add2 = cv2.add(a, b)  # OpenCV API operation\n",
    "sub2 = cv2.subtract(a, b)\n",
    "mult2 = cv2.multiply(a , 2)\n",
    "div2 = cv2.divide(a, 3)\n",
    "\n",
    "print('a = ', a, 'b = ' , b)\n",
    "print()\n",
    "print('np a + b = ', add1, ',                  cv2.add(a, b) = ' , add2)\n",
    "print('np a - b = ', sub1, ',                  cv2.subtract(a, b) = ', sub2)\n",
    "print('np a * 2 = ', mult1, ',                  cv2.multiply(a, 2) =', mult2)\n",
    "print('np a / 3 = ', div1, ',  cv2.divide(a, 3) = ', div2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the numpy calculation results and the calculation results using the OpenCV calculation function are different.  \n",
    "- The left side is the result of calculation with numpy, \n",
    "- and the right side is the result of calculation with the OpenCV function.\n",
    "\n",
    ">- 200 + 100 = 300, which exceeds 255. The value range of the unit8 type is 0 to 255, so values exceeding 255 are counted from 0 again.\n",
    ">- Calculating 200 + 100 with numpy is 300, which is 300 - 256 = 44.   \n",
    "\n",
    "- On the other hand, if you use the cv2.add() function, \n",
    "\n",
    ">- all values exceeding 255 will be returned as 255.\n",
    ">- 50 + 100 = 150, which has the same result whether numpy operation or cv2.add() operation. Because 150 does not exceed 255.  \n",
    ">- Similarly, 50 - 100 = -50, but the result of numpy operation is 206. Because -50 + 256 = 206.  \n",
    "\n",
    "- The result of calculation with cv2.subtract() is 0.   \n",
    "\n",
    ">- This is because OpenCV returns all values less than 0 as 0.  \n",
    "\n",
    "- Multiplication and division operations also do not take values greater than 255 or less than 0, and do not have decimal points.  \n",
    "\n",
    "When you pass a third parameter to the cv2.add() function, it assigns the sum of the first and second parameters to the third parameter.  \n",
    "\n",
    "Therefore, the results of the three codes below are the same:\n",
    "- c = cv2.add(a, b): Add a and b and assign to c\n",
    "- c = cv2.add(a, b, None): Add a and b and assign to None\n",
    "- cv2.add(a, b, c): Add a and b and assign to c  \n",
    "    \n",
    "※ If a numpy array is passed to the fourth parameter, mask, the operation is performed only on pixels at positions (indexes) where the mask value is not 0.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arithmatic_mask and accumulating computation\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([[1, 2]], dtype=np.uint8) \n",
    "b = np.array([[10, 20]], dtype=np.uint8)\n",
    "mask = np.array([[1, 0]], dtype=np.uint8) \n",
    "c1 = cv2.add(a, b, None, mask) # mask value (1, 0)\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = cv2.add(a, b, b.copy(), mask) # adds only the first element of a and b. the third parameter is b.copy() = [10, 20], leaving the second element of b alone. So the result is [[11, 20]].\n",
    "print(c2, b.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = cv2.add(a, b, b, mask) # adds only the first element of a and b -> 3rd b = (11, 0) -> b with mask(11,20) \n",
    "print(c3, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add only the first elements of a and b and apply to the first element of b,\n",
    "Leave the second element of b alone. So the results [[11, 20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"./images/practice_img/pencil_small.jpg\")\n",
    "number1 = np.ones_like(src) * 127 # grey(127, 127, 127) \n",
    "number2 = np.ones_like(src) * 2   # black(2, 2, 2) 사용\n",
    "img = src.copy()\n",
    "add = cv2.add(src, number1)\n",
    "sub = cv2.subtract(src, number1)\n",
    "mul = cv2.multiply(src, number2)\n",
    "div = cv2.divide(src, number2)\n",
    "\n",
    "src = np.concatenate((src, src, src, src), axis = 1)\n",
    "number = np.concatenate((number1, number1, number2, number2), axis = 1)\n",
    "dst = np.concatenate((add, sub, mul, div), axis = 1)\n",
    "\n",
    "dst = np.concatenate((src, number, dst), axis = 0)\n",
    "\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "titles = ['original', 'add+127', 'sub-127','mul*2','div /2']\n",
    "images = [img, add, sub, mul, div ]\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(titles[i]), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▶ Image Compare  \n",
    "\n",
    "There is no subtraction taking place only comparison  \n",
    "cv2.compare performs an element-wise comparison. In simple words, given the following instance:  \n",
    "- **cv2.compare(A, B, cv2.CMP_GT)**  \n",
    "\n",
    "every element in array A is compared with every element in array B.   \n",
    "The flag cv2.CMP_GT is used to check whether the element in A is greater than of B in each comparison. It returns another array containing 0 and 255; where\n",
    ">- 0 -> element in A is not greater than that in B  \n",
    ">- 255 -> element in A is greater than that in B  \n",
    "\n",
    "OpenCV limits the range between 0-255 internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"./images/practice_img/pencil_small.jpg\")\n",
    "number = np.ones_like(src) * 127\n",
    "img = src.copy()\n",
    "_max = cv2.max(src, number) \n",
    "_min = cv2.min(src, number) \n",
    "_abs = cv2.absdiff(src, number) \n",
    "compare1 = cv2.compare(src, number, cv2.CMP_GT) #  src > number True : 255,  False: 0\n",
    "# compare2 = cv2.compare(src, number, cv2.CMP_LT) #  src < number\n",
    "\n",
    "src = np.concatenate((src, src, src, src), axis = 1)\n",
    "number = np.concatenate((number, number, number, number), axis = 1)\n",
    "dst = np.concatenate((_max, _min, _abs, compare1), axis = 1)\n",
    "\n",
    "dst = np.concatenate((src, number, dst), axis = 0)\n",
    "\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "titles = ['original', '_max>127', '_min<127','_abs diff', 'compare1:GT', 'compare2:LT']\n",
    "images = [img, _max, _min, _abs, compare1, compare2 ]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(titles[i]), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The maximum (minimum) value function calculates the maximum (minimum) value for each element of the two images.\n",
    "- If the comparison result is True, change the value of the element to 255,   \n",
    "- and if the comparison result is False, change the value of the element to 0.\n",
    "\n",
    "### ● flags  \n",
    "\n",
    "Flag   | Meaning   \n",
    "-------|--------\n",
    "cv2.CMP_EQ|src = number\n",
    "cv2.CMP_NE|src ≠ number\n",
    "cv2.CMP_GT|src > number\n",
    "cv2.CMP_GE|src ≧ number\n",
    "cv2.CMP_LT|src < number\n",
    "cv2.CMP_LE|src ≦ number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When compositing two images, neither the sum of numpy nor the cv2.add() function seen above will give you good results.\n",
    "If you perform numpy's summation, if the pixel value is greater than 255, the image will be close to black because it will only have an excess value.\n",
    "\n",
    "For example, if you add 150 and 180 together, you get 330, so the final result is 74, which is the excess value at 255. This will cause some areas to be overwhelmed.\n",
    "On the other hand, if you do the cv2.add() operation, most of the pixel values will be close to 255. Thus, the image will be white overall.\n",
    "\n",
    "The code below shows such an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blending_simple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "img1 = cv2.imread('./images/practice_img/wing_wall.jpg')\n",
    "img2 = cv2.imread('./images/practice_img/yate.jpg')\n",
    "\n",
    "print(img1.shape, img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img3 = img1 + img2  \n",
    "img4 = cv2.add(img1, img2) \n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "imgs = {'img1':img1, 'img2':img2, 'img1+img2': img3, 'cv.add(img1, img2)': img4}\n",
    "\n",
    "for i, (k, v) in enumerate(imgs.items()):\n",
    "    plt.subplot(2,2, i + 1)\n",
    "    plt.imshow(v[:,:,::-1])\n",
    "    plt.title(k)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▶ Weighted Image Blending  \n",
    "\n",
    "This is also image addition, but different weights(alpha) are given to images so that it gives a feeling of blending or transparency.  \n",
    "Images are added as per the equation below:  \n",
    "\n",
    "$$ g(x) = (1 - \\alpha)f_{0}(x) + \\alpha f_{1}(x) $$\n",
    "\n",
    "By varying $\\alpha$ from 0 $\\rightarrow$ 1, you can perform a cool transition between one image to another.  \n",
    "Here I took two images to blend them together.  \n",
    "First image is given a weight of 0.7 and second image is given 0.3.  \n",
    "cv2.addWeighted() applies following equation on the image.  \n",
    "\n",
    "$$ dst = \\alpha \\cdot img1 + \\beta \\cdot img2 + \\gamma $$\n",
    "\n",
    "Here $\\gamma$ is taken as zero.\n",
    "\n",
    "~ Syntax:  \n",
    "    \n",
    "* **cv2.addWeight(img1, alpha, img2, beta, gamma)**  \n",
    "\n",
    "~ Parameters: \n",
    "    \n",
    "- img1, img2: imgs\n",
    "- alpha: weight value to img_1\n",
    "- beta: weight value to img_2 (1-alpha) \n",
    "- gamma: constant value, 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blending_alpha.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "alpha = 0.3 \n",
    "\n",
    "img1 = cv2.imread('./images/practice_img/wing_wall.jpg')\n",
    "img2 = cv2.imread('./images/practice_img/yate.jpg')\n",
    "\n",
    "blended = img1 * alpha + img2 * (1-alpha) # equation\n",
    "blended = blended.astype(np.uint8) \n",
    "cv2.imshow('img1 * alpha + img2 * (1-alpha)', blended)\n",
    "\n",
    "dst = cv2.addWeighted(img1, alpha, img2, (1-alpha), 0) # opencv\n",
    "cv2.imshow('cv2.addWeighted', dst)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(15,10))\n",
    "axs[0].imshow(blended), axs[0].axis('off'), axs[0].set_title('np_blended')\n",
    "axs[1].imshow(dst), axs[1].axis('off'), axs[1].set_title('addWeighted')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Image Blending\n",
    "\n",
    "img1 = cv2.imread('./images/dogs/04.jpg')\n",
    "img2 = cv2.imread('./images/cats/cat.jpg')\n",
    "img2_resized = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(img2_resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "dst1 = cv2.addWeighted(img1,0.7,img2,0.3,0)\n",
    "dst2 = cv2.addWeighted(img1,0.3,img2,0.7,0)\n",
    "\n",
    "fig, axs = plt.subplots(1,4,figsize=(10,10))\n",
    "axs[0].imshow(img1), axs[0].axis('off'), axs[0].set_title('img1')\n",
    "axs[1].imshow(img2), axs[1].axis('off'), axs[1].set_title('img2')\n",
    "axs[2].imshow(dst1), axs[2].axis('off'), axs[2].set_title('0.7_img1+0.3_img2')\n",
    "axs[3].imshow(dst2), axs[3].axis('off'), axs[3].set_title('0.3_img1+0.7_img2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "img1 = cv2.imread('./images/ml.png')\n",
    "img2 = cv2.imread('./images/OIP.png')\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(5,5))\n",
    "axs[0].imshow(img1), axs[0].axis('off'), axs[0].set_title('Org_1')\n",
    "axs[1].imshow(img2), axs[1].axis('off'), axs[1].set_title('Org_2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape, img2.shape # check img size and make same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_resized = cv2.resize(img2, (img1.shape[1], img1.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape, img2_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.addWeighted(img1,0.6,img2_resized,0.4,0)\n",
    "\n",
    "fig, axs = plt.subplots(1,3,figsize=(5,5))\n",
    "axs[0].imshow(img1), axs[0].axis('off'), axs[0].set_title('Org_1')\n",
    "axs[1].imshow(img2), axs[1].axis('off'), axs[1].set_title('Org_2')\n",
    "axs[2].imshow(dst), axs[2].axis('off'), axs[2].set_title('Adding 2 Imgs')\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.imshow(img2)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▶ Blending with Alpha Trackbar\n",
    "\n",
    "Moving the trackbar to adjust the alpha value to synthesize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blending_alpha_trackbar.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "win_name = 'Alpha blending'     \n",
    "trackbar_name = 'fade'          \n",
    "\n",
    "def onChange(x):\n",
    "    alpha = x/100\n",
    "    dst = cv2.addWeighted(img1, 1-alpha, img2, alpha, 0) \n",
    "    cv2.imshow(win_name, dst)\n",
    "\n",
    "img1 = cv2.imread('./images/practice_img/man_face.jpg')\n",
    "img2 = cv2.imread('./images/practice_img/lion_face.jpg')\n",
    "\n",
    "cv2.imshow(win_name, img1)\n",
    "cv2.createTrackbar(trackbar_name, win_name, 0, 100, onChange)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▶ Bitwise arithmetics  \n",
    "\n",
    "Bitwise arithmetic helps with selective computations, such as selecting only certain regions or excluding only certain regions when compositing two images.   \n",
    "\n",
    "<img src = './images/practice_img/bitwise.jpeg' width=400 height=400> \n",
    "\n",
    "\n",
    " https://slideplayer.com/slide/5378944/  \n",
    "\n",
    "~ Syntax:  \n",
    "    \n",
    ">- cv2.bitwise_and(img1, img2, mask=None)  \n",
    ">- cv2.bitwise_or(img1, img2, mask=None)\n",
    ">- cv2.bitwise_xor(img1, img2, mask=None)  \n",
    ">- cv2.bitwise_not(img1, img2, mask=None)  \n",
    "\n",
    "~ Parameters:  \n",
    "\n",
    ">- img1, img2 : same shape imgs\n",
    ">- mask : calulate only not 0 pxls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bitwise.py\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "img1 = np.zeros((200,400), dtype=np.uint8) # all black img\n",
    "img2 = np.zeros((200,400), dtype=np.uint8)\n",
    "img1[:, :200] = 255         # left half white(255), right half black(0)\n",
    "img2[100:200, :] = 255      # above half black(0), bottom half white(255)\n",
    "\n",
    "bitAnd = cv2.bitwise_and(img1, img2)\n",
    "bitOr = cv2.bitwise_or(img1, img2)\n",
    "bitXor = cv2.bitwise_xor(img1, img2)\n",
    "bitNot = cv2.bitwise_not(img1)\n",
    "\n",
    "imgs = {'img1':img1, 'img2':img2, 'and':bitAnd, 'or':bitOr, 'xor':bitXor, 'not(img1)':bitNot}\n",
    "for i, (title, img) in enumerate(imgs.items()):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    plt.title(title)\n",
    "    plt.imshow(img, 'gray')\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 is black, 255 is white.   \n",
    "- Substituting a boolean value is False for 0 and True for a non-zero value.   \n",
    "- Therefore, black is 0, which means False, and white is 255, which means True.   \n",
    "- Both values must be true in order for the AND operation of two values to be True.   \n",
    "- Therefore, after the AND operation, only the white part of img1 and img2 overlaps in white.\n",
    "\n",
    "    0은 검은색, 255은 흰색입니다.   \n",
    "    - 불리언(boolean) 값으로 치환하면 0은 False, 0이 아닌 값은 True입니다.   \n",
    "    - 따라서 검은색은 0이므로 False를 의미하고, 흰색은 255이므로 True를 의미합니다.   \n",
    "    - 두 값의 AND 연산 결과 True가 되기 위해서는 두 값 모두 True여야 합니다.   \n",
    "    - 따라서 AND 연산 후에는 img1과 img2의 흰색 부분이 겹치는 곳만 흰색으로 표시됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of using bitwise operation to remove a part of an image into the desired shape\n",
    "비트와이즈 연산으로 이미지 일부분을 원하는 모양으로 떼어내는 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ● Bitwise masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bitwise_masking.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "img = cv2.imread('./images/practice_img/eiffel_tower.jpg')\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('img')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(img) # all 0 black img\n",
    "cv2.circle(mask, (400,200), 150, (255,255,255), -1) # mask area : 255 (white, filled circle)\n",
    "masked = cv2.bitwise_and(img, mask) # only the both area has pxl values : true\n",
    "\n",
    "cv2.imshow('original', img)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('masked', masked)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "masked = cv2.cvtColor(masked, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, axs = plt.subplots(1,3,figsize=(15,10))\n",
    "axs[0].imshow(img), axs[0].axis('off'), axs[0].set_title('original')\n",
    "axs[1].imshow(mask), axs[1].axis('off'), axs[1].set_title('mask')\n",
    "axs[2].imshow(masked), axs[2].axis('off'), axs[2].set_title('masked img')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▶ Masked Blending Img \n",
    "\n",
    "Let's learn how to combine two images (4 channels) with a background and a foreground (the object image). \n",
    "\n",
    "● Typically, one image is divided into a background and a foreground (the actual image, not the background). \n",
    "- For example, consider an image of a dog on green grass.   \n",
    "- The green grass is in the background, the dog is in the foreground.   \n",
    "- What if what we want is a puppy instead of green grass? \n",
    "- Only puppies should be extracted from the image. \n",
    "\n",
    "● First of all, let's use an image with a transparent background and composit. \n",
    "- In the BGRA color format, A (alpha) is 0 for the background and A (alpha) is 255 for the foreground. \n",
    "- This is because A is transparent if it is 0, and it is opaque if it is 255.   \n",
    "- With BGRA, you can easily cut out the background. \n",
    "\n",
    "     ● 배경과 전경(배경이 아닌 실제 이미지)이 있는 4 채널의 두 이미지를 합성하는 방법에 대해 배워보겠습니다. \n",
    "    일반적으로 하나의 이미지는 배경과 전경(배경이 아닌 실제 이미지)으로 나뉩니다. \n",
    "    예를 들어 푸른 잔디에 강아지가 있는 이미지를 생각해봅시다. 푸른 잔디는 배경이고, 강아지는 전경입니다. \n",
    "    우리가 원하는 게 푸른 잔디가 아닌 강아지라면 어떻게 해야 할까요? \n",
    "    이미지에서 강아지만을 추출해야 합니다. \n",
    "\n",
    "    • 우선 배경이 투명한 이미지를 활용하여 합성해보겠습니다.   \n",
    "    • BGRA 색상 형식으로 표현할 때, 배경은 A(알파, alpha)가 0이고, 전경은 A(알파)가 255입니다.   \n",
    "    • A가 0이면 투명하고, 255면 불투명하기 때문입니다. BGRA를 활용하면 배경을 손쉽게 오려낼 수 있습니다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  combine_rgba_mask.py 투명 배경 PNG 파일을 이용한 합성\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img_fg = cv2.imread('./images/practice_img/opencv_logo.png', cv2.IMREAD_UNCHANGED) # 4 chnl png file\n",
    "img_bg = cv2.imread('./images/practice_img/eiffel_tower.jpg')\n",
    "\n",
    "_, mask = cv2.threshold(img_fg[:,:,3], 1, 255, cv2.THRESH_BINARY) # cv2.threshold(img, threshold_value, value, flag)\n",
    "# If it is greater than threshold, it is value, or replace it with 0.\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "img_fg = cv2.cvtColor(img_fg, cv2.COLOR_BGRA2BGR) \n",
    "h, w = img_fg.shape[:2]\n",
    "roi = img_bg[10:10+h, 10:10+w ]\n",
    "\n",
    "masked_fg = cv2.bitwise_and(img_fg, img_fg, mask=mask) \n",
    "masked_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "added = masked_fg + masked_bg      \n",
    "img_bg[10:10+h, 10:10+w] = added\n",
    "\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('mask_inv', mask_inv)\n",
    "cv2.imshow('masked_fg', masked_fg)\n",
    "cv2.imshow('masked_bg', masked_bg)\n",
    "cv2.imshow('added', added)\n",
    "cv2.imshow('result', img_bg)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "fig, axs = plt.subplots(1,5,figsize=(15,10))\n",
    "axs[0].imshow(mask), axs[0].axis('off'), axs[0].set_title('mask')\n",
    "axs[1].imshow(mask_inv,cmap='gray'), axs[1].axis('off'), axs[1].set_title('mask_inv')\n",
    "axs[2].imshow(masked_fg), axs[2].axis('off'), axs[2].set_title('masked_fg')\n",
    "axs[3].imshow(masked_bg), axs[3].axis('off'), axs[3].set_title('masked_bg')\n",
    "axs[4].imshow(added), axs[4].axis('off'), axs[4].set_title('added')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img_bg, cv2.COLOR_BGR2RGB)),plt.axis('off'), plt.title('result')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "● cv2.threshod(img_fg[:, :, 3], 1, 255, cv2.THRESH_BINARY)\n",
    "- cv2.threshold(img, threshold_value, value, flag)\n",
    "- If it is greater than threshold, it is value, or replace it with 0.\n",
    "- Create a mask that separates the background from the foreground\n",
    "\n",
    "● The image that says OpenCV has a transparent background.   \n",
    "- Therefore, the background part has an A value of 0 in BRGA. \n",
    "- On the other hand, the foreground part, not the background, is not a zero.   \n",
    "- So, if A is more than 1, it will be 255, and if it is less than 1, it will be 0,   \n",
    "- and the background will be black and the foreground will be white. \n",
    "\n",
    "● mask_inv = cv2.bitwise_not (mask), so mask_inv is the opposite of mask.\n",
    "- That is, the background is white and the foreground is black.   \n",
    "- These two masks were used to composite the Paris image and the OpenCV image\n",
    "\n",
    "    ● cv2.threshold(img, threshold_value, value, flag)로 전경을 분리하는 마스크를 만듭니다.  \n",
    "    - OpenCV라고 쓰여있는 이미지는 배경이 투명합니다.   \n",
    "    - 따라서 배경 부분은 BRGA의 A값이 0입니다. \n",
    "    - 반면 배경이 아닌 전경 부분은 A가 0이 아닙니다.   \n",
    "    - 따라서 A가 1 이상이면 255, 1 미만이면 0으로 바꾸어주면 배경은 검은색, 전경은 흰색이 됩니다.  \n",
    "\n",
    "    ● mask_inv = cv2.bitwise_not(mask)이므로 mask_inv는 mask의 반대입니다. \n",
    "    - 즉, 배경은 흰색, 전경은 검은색입니다.   \n",
    "    - 이 두 mask를 활용하여 파리 이미지와 OpenCV 이미지를 합성했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▶ Chroma key Masking and Blending  \n",
    "\n",
    "The color-based masking method is called chroma key.  \n",
    "For example, an actor shoots a green background and then later composites the green background with another background.   \n",
    "\n",
    "색상을 이용한 마스킹 방식을 **크로마키(chroma key)**라고 합니다.  \n",
    "예를 들어, 초록색 배경을 두고 배우가 촬영한 뒤 나중에 초록색 배경은 다른 배경과 합성하는 방식입니다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chromakey.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "img1 = cv2.imread('./images/practice_img/man_chromakey.jpg')\n",
    "img2 = cv2.imread('./images/practice_img/street.jpg')\n",
    "\n",
    "img1_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "fig, axs = plt.subplots(1,2,figsize=(8,8))\n",
    "axs[0].imshow(img1_rgb), axs[0].axis('off'), axs[0].set_title('img1_rgb')\n",
    "axs[1].imshow(img2_rgb), axs[1].axis('off'), axs[1].set_title('img2_rgb')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height1, width1 = img1.shape[:2]\n",
    "height2, width2 = img2.shape[:2]\n",
    "x = (width2 - width1)//2\n",
    "y = height2 - height1\n",
    "w = x + width1\n",
    "h = y + height1\n",
    "\n",
    "chromakey = img1[:10, :10, :] # chromakey ROI with 10 pxls\n",
    "offset = 20\n",
    "\n",
    "hsv_chroma = cv2.cvtColor(chromakey, cv2.COLOR_BGR2HSV) # change to HSV\n",
    "hsv_img = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "#chroma_h = hsv_chroma[0]\n",
    "chroma_h = hsv_chroma[:,:,0]\n",
    "lower = np.array([chroma_h.min()-offset, 100, 100])\n",
    "upper = np.array([chroma_h.max()+offset, 255, 255])\n",
    "\n",
    "mask = cv2.inRange(hsv_img, lower, upper)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "roi = img2[y:h, x:w]\n",
    "fg = cv2.bitwise_and(img1, img1, mask=mask_inv)\n",
    "bg = cv2.bitwise_and(roi, roi, mask=mask)\n",
    "img2[y:h, x:w] = fg + bg\n",
    "\n",
    "cv2.imshow('chromakey', img1)\n",
    "cv2.imshow('added', img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "img1_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "fig, axs = plt.subplots(1,2,figsize=(15,10))\n",
    "axs[0].imshow(img1_rgb), axs[0].axis('off'), axs[0].set_title('chromakey')\n",
    "axs[1].imshow(img2_rgb), axs[1].axis('off'), axs[1].set_title('added')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▶ **cv2.seamlessClone()**  \n",
    "\n",
    "Image synthesis requires blending and masking as you see the above.   \n",
    "However, choosing alpha values for blending, coordinates for masking, and color selection takes a lot of time.  \n",
    "\n",
    "In OpenCV, there is a function called **cv2.seamlessClone()**, which functions to synthesize the characteristics of two images by itself.\n",
    "-  There is no need to select alpha values for blending, coordinates for masking, and color selection\n",
    "\n",
    "There is a function called cv2.seamlessClone()**, which functions to combine the characteristics of two images on its own.\n",
    "\n",
    "    이미지 합성에는 블렌딩과 마스킹이 필요합니다.   \n",
    "    하지만, 블렌딩을 위한 알파 값 선택과 마스킹을 위한 좌표, 색상 선택에는 많은 시간이 소요됩니다.  \n",
    "    **cv2.seamlessClone()**이라는 함수가 있는데 이는 두 이미지의 특징을 살려 알아서 합성하는 기능을 합니다.\n",
    "\n",
    "~ Syntax:\n",
    "- **dst = cv2.seamlessClone(src, dst, mask, coords, flags, output)**\n",
    "\n",
    "~ Parameters:  \n",
    "    \n",
    ">- src: input img, foreground\n",
    ">- dst: out img, background\n",
    ">- mask: mask, The area you want to synthesize in src is 255, and the rest is 0\n",
    ">- coords: The coordinates of the dst where src wants to be placed. (center)\n",
    ">- flags: Synthesis method\n",
    ">>- cv2.NORMAL_CLONE : Preserve the input source  \n",
    ">>- cv2.MIXED_CLONE : Mix inputs and targets       \n",
    ">- output(optional): result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seamlessclone.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    " \n",
    "img1 = cv2.imread(\"./images/practice_img/drawing.jpg\")\n",
    "img2= cv2.imread(\"./images/practice_img/my_hand.jpg\")\n",
    "img1_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "fig, axs = plt.subplots(1,2,figsize=(8,8))\n",
    "axs[0].imshow(img1_rgb), axs[0].axis('off'), axs[0].set_title('img1_rgb')\n",
    "axs[1].imshow(img2_rgb), axs[1].axis('off'), axs[1].set_title('img2_rgb')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.full_like(img1, 255)\n",
    " \n",
    "height, width = img2.shape[:2] \n",
    "center = (width//2, height//2) # img center\n",
    "\n",
    "normal = cv2.seamlessClone(img1, img2, mask, center, cv2.NORMAL_CLONE) # seamlessClone\n",
    "mixed = cv2.seamlessClone(img1, img2, mask, center, cv2.MIXED_CLONE)\n",
    "\n",
    "cv2.imshow('normal', normal)\n",
    "cv2.imshow('mixed', mixed)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "normal_rgb = cv2.cvtColor(normal, cv2.COLOR_BGR2RGB)\n",
    "mixed_rgb = cv2.cvtColor(mixed, cv2.COLOR_BGR2RGB)\n",
    "fig, axs = plt.subplots(1,2,figsize=(10,10))\n",
    "axs[0].imshow(normal_rgb), axs[0].axis('off'), axs[0].set_title('cv2.NORMAL_CLONE')\n",
    "axs[1].imshow(mixed_rgb), axs[1].axis('off'), axs[1].set_title('cv2.MIXED_CLONE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▶ Find the difference between two images  \n",
    "\n",
    "Subtracting the pixel values of the two images gives a negative number, so you need to take the absolute value.  \n",
    "\n",
    "~ Syntax:  \n",
    "    \n",
    "* **diff = cv2.absdiff(img1, img2)**  \n",
    "\n",
    "~ Parameters: \n",
    "    \n",
    "- img1, img2: imgs\n",
    "- diff: absolute value\n",
    "\n",
    "~ Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_absolute.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread('./images/practice_img/robot_arm1.jpg')\n",
    "img2 = cv2.imread('./images/practice_img/robot_arm2.jpg')\n",
    "img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "diff = cv2.absdiff(img1_gray, img2_gray) # find differences of imgs\n",
    "\n",
    "_, diff = cv2.threshold(diff, 1, 255, cv2.THRESH_BINARY) # threshold and (inc differences)\n",
    "diff_red = cv2.cvtColor(diff, cv2.COLOR_GRAY2BGR)  # convert to color\n",
    "diff_red[:,:,2] = 0\n",
    "\n",
    "spot = cv2.bitwise_xor(img2, diff_red) # marking on spot\n",
    "\n",
    "cv2.imshow('img1', img1)\n",
    "cv2.imshow('img2', img2)\n",
    "cv2.imshow('diff', diff)\n",
    "cv2.imshow('spot', spot)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "spot_rgb = cv2.cvtColor(spot, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15,10))\n",
    "axs[0, 0].imshow(img1),axs[0, 0].axis('off'),axs[0, 0].set_title('Original img1')\n",
    "axs[0, 1].imshow(img2),axs[0, 1].axis('off'),axs[0, 1].set_title('Original img2')\n",
    "axs[1, 0].imshow(diff,cmap='gray'), axs[1, 0].axis('off'), axs[1, 0].set_title('Differences')\n",
    "axs[1, 1].imshow(spot_rgb), axs[1, 1].axis('off'), axs[1, 1].set_title('Different Spot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▶ Reverse Image  \n",
    "\n",
    "Reverse Image is used to convert a video or image to an inverted color.  \n",
    "Each pixel is subjected to a bitwise operation, among which the NOT operation is applied.  \n",
    "The NOT operation is an operation that reverses the value of each digit.  \n",
    ">- If you apply the NOT operation to a pixel with a value of 153, it will be changed to a value of 102.\n",
    ">>- 153 has a value of 0b10011001, and 102 has a value of 0b01100110.\n",
    ">- That is, you change the pixel value of the decimal digit to the value of the binary number, and then reverse the value of each digit.\n",
    ">- 1 becomes 0, 0 changes to 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "src1 = cv2.imread(\"./images/practice_img/motorcycle.jpg\", cv2.IMREAD_COLOR) # pencil_small.jpg motorcycle.jpg butterfly.webp\n",
    "# src2 = cv2.imread(\"./images/practice_img/pistol.png\", cv2.IMREAD_COLOR) \n",
    "\n",
    "img_not = cv2.bitwise_not(src1)\n",
    "# img_and = cv2.bitwise_and(src1,src2)\n",
    "# img_or = cv2.bitwise_or(src1,src2)\n",
    "# img_xor = cv2.bitwise_xor(src1,src2)\n",
    "\n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "plt.subplot(121),plt.imshow(cv2.cvtColor(src1, cv2.COLOR_BGR2RGB)),plt.title('original'),plt.axis('off')\n",
    "plt.subplot(122),plt.imshow(cv2.cvtColor(img_not, cv2.COLOR_BGR2RGB)),plt.title('img_not'),plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV-py36",
   "language": "python",
   "name": "cv_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
