{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> ðŸ‘‰ class_02_1 IP Â» _Basic Operations - Images_ </center>\n",
    "\n",
    "## â–£ Basic Operations On images  \n",
    "\n",
    "In this class, we are going to discuss some of the basic operations that we can do on the images once we have successfully read them.The operations we are going to do here ae:\n",
    "\n",
    ">â–¸ Reading / Displaying / Writing / Saving an Image   \n",
    ">â–¸ Change the color shape  \n",
    ">â–¸ Resize/Rotate/Draw Function   \n",
    ">â–¸ Access pixel values and modify them  \n",
    ">â–¸ Access image properties  \n",
    ">â–¸ Set a Region of Interest (ROI)  \n",
    ">â–¸ Split and merge image channels  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Reading and Displaying an image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 # OpenCV-Python\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"OpenCV-Python Version %s\" % cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_logo = plt.imread('./images/matplotlib-logo.png',cv2.IMREAD_COLOR)\n",
    "cv_logo = plt.imread('./images/OIP.png',cv2.IMREAD_COLOR)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.subplot(1,2,1),plt.imshow(plt_logo),plt.axis('off')\n",
    "plt.subplot(1,2,2),plt.imshow(cv_logo),plt.axis('off')\n",
    "# plt.subplot(1,3,3),plt.imshow(travel),plt.axis('off')\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â— Read/Display Using **_OpenCV_**\n",
    ">### â–  <mark>**cv2.imread('filename', flag)**</mark> : _A function that reads an image and turns it into a Numpy object_   \n",
    ">> ### â–¸ flag options:           \n",
    ">>* **cv2.IMREAD_COLOR (1)** : load a color image. Any transparency of image will be neglected. It is the default flag.  \n",
    ">>* **cv2.IMREAD_GRAYSCALE (0)** : load image in grayscale mode\n",
    ">>* **cv2.IMREAD_UNCHANGED (-1)** : load image including alpha channel\n",
    ">>* cv2.IMREAD_ANYDEPTH : Use precision as 16/32 bits or 8 bits, depending on the image\n",
    ">>* cv2.IMREAD_ANYCOLOR : 3 channels available, used as color images\n",
    ">>* cv2.IMREAD_REDUCED_GRAYSCALE_2 : 1 channel, 1/2 size, grayscale application\n",
    ">>* cv2.IMREAD_REDUCED_GRAYSCALE_4 : 1 channel, 1/4 size, grayscale application\n",
    ">>* cv2.IMREAD_REDUCED_GRAYSCALE_8 : 1 channel, 1/8 size, grayscale application\n",
    ">>* cv2.IMREAD_REDUCED_COLOR_2 :3 channels, 1/2 size, using BGR images\n",
    ">>* cv2.IMREAD_REDUCED_COLOR_4 : 3 channels, 1/4 size, using BGR images\n",
    ">>* cv2.IMREAD_REDUCED_COLOR_8 : 3 channels, 1/8 size, using BGR images     \n",
    ">### â–  <mark>**cv2.imshow('windowname', image)**</mark> : _A function that shows a specific image to the windowname_\n",
    ">### â–  <mark>**cv2.imwrite('filename.png/jpg/...', image)**</mark> : _Save image as a file_    \n",
    ">### â–  <mark>**cv2.cvtColor(image, flag)**</mark> : _A function to change the color shape of an image_    \n",
    ">> ### â–¸ flag options:           \n",
    ">>* cv2.COLOR_BGR2RGB  or   4 : change BGR to RGB \n",
    ">>* cv2.COLOR_BGR2GRAY or   6 : change BGR to Gray \n",
    ">>* cv2.COLOR_RGB2GRAY or   7 : change RGB to Gray \n",
    ">>* cv2.COLOR_GRAY2RGB or   8 : change Gray to RGB  \n",
    ">> âž¡ï¸https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html    \n",
    ">### â–  **cv2.waitKey():** is a keyboard binding function. \n",
    ">- It's argument is the time in milliseconds.   \n",
    ">- The function waits for specified milliseconds for any keyboard event.   \n",
    ">- If you press any key in that time, the program continues.     \n",
    ">- If 0 is passed, it waits indefinitely for a key stroke.\n",
    "\n",
    ">### â–  **cv2.destroyAllWindows():**  simply destroys all the windows we created.   \n",
    ">- If you want to destroy any specific window, use the function cv2.destroyWindow() where you pass the exact window name as the argument.  \n",
    ">- There is **a special case** where you can already create a window and load image to it later. In that case, you can specify whether window is resizable or not. It is done with the function cv2.namedWindow(). By default, the flag is cv2.WINDOW_AUTOSIZE. But if you specify flag to be cv2.WINDOW_NORMAL, you can resize window. It will be helpful when image is too large in dimension and adding track bar to windows.  \n",
    "\n",
    "### â€» OpenCV follows BGR order, while matplotlib follows RGB order. ðŸ˜‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â— Read/Display Using **_Matplot_**   \n",
    "\n",
    ">### â–  <mark>**plt.imread(filename, flag)**</mark> : _A function that reads an image and turns it into a Numpy object_   \n",
    ">> â–¸ flag options: same as OpenCV\n",
    ">### â–  <mark>**plt.imshow(image)**</mark> : img title - plt.title('img title')\n",
    ">### â–  <mark>**plt.imsave(filename, image)**</mark> : _Save image as a file_\n",
    ">### â–  <mark>**plt.imshow(image, cmap='gray')**</mark> : _change the color shape_ âž¡ï¸ [colors](https://matplotlib.org/stable/tutorials/index)  \n",
    "\n",
    "### â€» We use both OpenCV(functions) and Matplotlib(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â–  Examples:  \n",
    "- cv2.imread('filename', flag)  \n",
    "- cv2.imshow('windowname', image)  \n",
    "- plt.imshow(image)  \n",
    "- cv2.imwrite('filename.png/jpg/...', image)  \n",
    "- cv2.cvtColor(image, flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_show.py\n",
    "import cv2\n",
    "\n",
    "img_file = \"./images/lady.jpg\" \n",
    "img = cv2.imread(img_file)    \n",
    "\n",
    "if img is not None:\n",
    "    cv2.imshow('IMG', img)     \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print('No image file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('./images/ex01.jpg')  \n",
    "image_plt = plt.imread('./images/ex01.jpg')\n",
    "\n",
    "image.shape, image_plt.shape # height, width and channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = image.shape[:2] # Extracting the height and width of an image\n",
    "print(\"Height = {},  Width = {}\".format(h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.show() # BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"./images/gk-pic01.png\", cv2.IMREAD_COLOR)\n",
    " \n",
    "                            # Creating GUI window to display an image on screen\n",
    "cv2.imshow(\"image\", img)    # first Parameter is windows title (should be in string format) and Second Parameter is image array\n",
    " \n",
    "                # To hold the window on screen, we use cv2.waitKey method\n",
    "cv2.waitKey(0)  # First Parameter is for holding screen for specified milliseconds. It should be positive integer.\n",
    "                # If 0 pass an parameter, then it will hold the screen until user close it.\n",
    "\n",
    "cv2.destroyAllWindows() # It is for removing/deleting created GUI window from screen and memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_plt_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(15,15))\n",
    "axs[0].imshow(image), axs[0].axis('off'), axs[0].set_title('BGR')\n",
    "axs[1].imshow(image_plt_rgb), axs[1].axis('off'), axs[1].set_title('RGB')\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.imshow(image_plt_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "img_org = cv2.imread('./images/practice_img/house.jpg',1)\n",
    "img_gray2 = cv2.imread('./images/practice_img/house.jpg',cv2.IMREAD_REDUCED_GRAYSCALE_2 )\n",
    "img_gray4 = cv2.imread('./images/practice_img/house.jpg',cv2.IMREAD_REDUCED_GRAYSCALE_4 )\n",
    "img_gray8 = cv2.imread('./images/practice_img/house.jpg',cv2.IMREAD_REDUCED_GRAYSCALE_8 )\n",
    "\n",
    "img_col2 = cv2.imread('./images/practice_img/house.jpg',cv2.IMREAD_REDUCED_COLOR_2 )\n",
    "img_col4 = cv2.imread('./images/practice_img/house.jpg',cv2.IMREAD_REDUCED_COLOR_4 )\n",
    "img_col8 = cv2.imread('./images/practice_img/house.jpg',cv2.IMREAD_REDUCED_COLOR_8 )\n",
    "# print(img_org.shape, img_gray2.shape, img_gray4.shape,img_gray8.shape)\n",
    "print(img_org.shape, img_col2.shape, img_col4.shape,img_col8.shape)\n",
    "\n",
    "cv2.imshow('original', img_org)\n",
    "cv2.imshow('1/2', img_gray2)\n",
    "cv2.imshow('1/4', img_gray4)\n",
    "cv2.imshow('1/8', img_gray8)\n",
    "cv2.imshow('1/2', img_col2)\n",
    "cv2.imshow('1/4', img_col4)\n",
    "cv2.imshow('1/8', img_col8)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "plt.subplot(141),plt.imshow(cv2.cvtColor(img_org, cv2.COLOR_BGR2RGB)),plt.title('original'),plt.axis('on')\n",
    "plt.subplot(142),plt.imshow(img_gray2, cmap='gray'),plt.title('1/2'),plt.axis('on')\n",
    "plt.subplot(143),plt.imshow(img_gray4, cmap='gray'),plt.title('1/4'),plt.axis('on')\n",
    "plt.subplot(144),plt.imshow(img_gray8, cmap='gray'),plt.title('1/8'),plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "plt.subplot(141),plt.imshow(cv2.cvtColor(img_org, cv2.COLOR_BGR2RGB)),plt.title('original'),plt.axis('on')\n",
    "plt.subplot(142),plt.imshow(cv2.cvtColor(img_col2, cv2.COLOR_BGR2RGB)),plt.title('1/2'),plt.axis('on')\n",
    "plt.subplot(143),plt.imshow(cv2.cvtColor(img_col4, cv2.COLOR_BGR2RGB)),plt.title('1/4'),plt.axis('on')\n",
    "plt.subplot(144),plt.imshow(cv2.cvtColor(img_col8, cv2.COLOR_BGR2RGB)),plt.title('1/8'),plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "img_cv = cv2.imread(\"./images/gk-pic01.png\", -1) \n",
    "img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB) # To convert BGR to RGB\n",
    "img_gray = cv2.imread(\"./images/gk-pic01.png\", cv2.IMREAD_GRAYSCALE) # convert to GRAY:\n",
    "# img_gray2 = cv2.imread(\"./images/bgr.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Displaying images\n",
    "fig, axs = plt.subplots(1,3,figsize=(15,10))\n",
    "axs[0].imshow(img_cv), axs[0].axis('off'), axs[0].set_title('Matplot fm cv(BGR)')\n",
    "axs[1].imshow(img_rgb), axs[1].axis('off'), axs[1].set_title('img_RGB')\n",
    "axs[2].imshow(img_gray), axs[2].axis('off'), axs[2].set_title('img_GRAY')\n",
    "# axs[3].imshow(img_gray2), axs[3].axis('off'), axs[3].set_title('img_GRAY')\n",
    "\n",
    "plt.imshow(img_cv),plt.imshow(img_rgb),plt.imshow(img_gray, cmap = 'gray')#,plt.imshow(img_gray2)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Saving an image   \n",
    "\n",
    "### â–  cv2.imwrite('filename.png/jpg/...', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_write.py\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"./images/lady.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow('Lady_gray', img)\n",
    "cv2.imwrite(\"./images/lady_gray.jpg\", img) #íŒŒì¼ë¡œ ì €ìž¥, í¬ë§·ì€ í™•ìž¥ì— ë”°ë¦„\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave('./results/Dog_BGR.png', image)\n",
    "cv2.imwrite('./results/Dog_RGB.jpg', image_plt_rgb)\n",
    "# If the file is successfully written then this function returns True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Change the color shape of an image   \n",
    "\n",
    "### â–  cv2.cvtColor(image, flag)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./images/ex01.jpg', -1)\n",
    "b,g,r = cv2.split(img)\n",
    "img2 = cv2.merge([r,g,b])\n",
    "plt.subplot(121);plt.imshow(img) # expects distorted color\n",
    "plt.subplot(122);plt.imshow(img2) # expect true color\n",
    "plt.show()\n",
    "\n",
    "cv2.imshow('bgr image',img) # expects true color\n",
    "cv2.imshow('rgb image',img2) # expects distorted color\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_RGB=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "fig, axs = plt.subplots(1,3,figsize=(20,15))\n",
    "axs[0].imshow(img), axs[0].axis('off'), axs[0].set_title('img_org_BGR')\n",
    "axs[1].imshow(img_RGB), axs[1].axis('off'), axs[1].set_title('img_RGB')\n",
    "axs[2].imshow(img_grayscale), axs[2].axis('off'), axs[2].set_title('img_grayscale')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.imshow(img_RGB)\n",
    "plt.imshow(img_grayscale, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â–  function using np.dot()  \n",
    "\n",
    "rgb2gray function converts RGB values to grayscale values by weighting the R, G, and B components to create a sum.\n",
    "\n",
    "> **$$ 0.2989 * R + 0.5870 * G + 0.1140 * B $$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "img_cv = cv2.imread('./images/ex01.jpg', -1)\n",
    "img_pl = plt.imread('./images/ex01.jpg', -1)\n",
    "img_cv_RGB = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# converting the image to monochrome\n",
    "img_pl_gray = rgb2gray(img_pl)\n",
    "\n",
    "fig, axs = plt.subplots(1,4,figsize=(15,10))\n",
    "axs[0].imshow(img_cv), axs[0].axis('off'), axs[0].set_title('img_cv(BGR)')\n",
    "axs[1].imshow(img_pl), axs[1].axis('off'), axs[1].set_title('img_pl(RGB)')\n",
    "axs[2].imshow(img_cv_RGB), axs[2].axis('off'), axs[2].set_title('mat_cv2RGB')\n",
    "axs[3].imshow(img_pl_gray, cmap='gray'), axs[3].axis('off'), axs[3].set_title('img_pl_gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_logo_cv = cv2.imread('./images/OIP.png',-1)\n",
    "op_logo_pl = plt.imread('./images/OIP.png',-1)\n",
    "op_logo_cv_0 = cv2.imread('./images/OIP.png',0)\n",
    "\n",
    "op_logo_cv_GRAY = cv2.cvtColor(op_logo_cv, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "fig, axs = plt.subplots(1,5,figsize=(10,5))\n",
    "axs[0].imshow(op_logo_cv), axs[0].axis('off'), axs[0].set_title('OP_cv')\n",
    "axs[1].imshow(op_logo_pl), axs[1].axis('off'), axs[1].set_title('OP_pl')\n",
    "axs[2].imshow(op_logo_cv_0), axs[2].axis('off'), axs[2].set_title('OP_cv_0_read')\n",
    "axs[3].imshow(op_logo_cv_0, cmap='gray'), axs[3].axis('off'), axs[3].set_title('OP_cv_0_GRAY')\n",
    "axs[4].imshow(op_logo_cv_GRAY, cmap='gray'), axs[4].axis('off'), axs[4].set_title('OP_cv_GRAY')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Waitkey & Window  \n",
    "### â–  cv2.WINDOW_NORMAL & cv2.WINDOW_AUTOSIZE\n",
    "\n",
    "There is a special case where you can already create a window and load image to it later. In that case, you can specify whether window is resizable or not. It is done with the function cv2.namedWindow(). By default, the flag is cv2.WINDOW_AUTOSIZE. But if you specify flag to be cv2.WINDOW_NORMAL, you can resize window. It will be helpful when image is too large in dimension and adding track bar to windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/ex01.jpg',-1)\n",
    "\n",
    "cv2.namedWindow('image WINDOW_NORMAL', cv2.WINDOW_NORMAL)\n",
    "# cv2.namedWindow('image', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow('image WINDOW_NORMAL',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_show_gray.py\n",
    "\n",
    "import cv2\n",
    "\n",
    "img_file = \"./images/lady.jpg\" \n",
    "img = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)    # íšŒìƒ‰ìœ¼ë¡œ ì½ê¸°\n",
    "\n",
    "if img is not None:\n",
    "    cv2.imshow('IMG', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print('No image file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Gray and save it\n",
    "import cv2\n",
    " \n",
    "img_org = cv2.imread('./images/ex01.jpg',-1)\n",
    "img_grayscale = cv2.imread('./images/ex01.jpg',0)\n",
    " \n",
    "cv2.imshow('org image',img_org)\n",
    "cv2.imshow('graycsale image',img_grayscale)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imwrite('./results/ex01_grayscale.jpg',img_grayscale) # The function cv2.imwrite() is used to write an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_RGB=cv2.cvtColor(img_org, cv2.COLOR_BGR2RGB)\n",
    "fig, axs = plt.subplots(1,3,figsize=(15,10))\n",
    "axs[0].imshow(img_org), axs[0].axis('off'), axs[0].set_title('img_org_BGR')\n",
    "axs[1].imshow(img_RGB), axs[1].axis('off'), axs[1].set_title('img_RGB')\n",
    "axs[2].imshow(img_grayscale), axs[2].axis('off'), axs[2].set_title('img_grayscale')\n",
    "\n",
    "plt.imshow(img_org)\n",
    "plt.imshow(img_RGB)\n",
    "plt.imshow(img_grayscale, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below program loads an image in colorscale, displays it, save the image if you press â€˜sâ€™ and exit, or simply exit without saving if you press ESC key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('./images/cats/cats_1.jpg',-1)\n",
    "img_cat_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "cv2.imshow('image_color',img)\n",
    "cv2.imshow('image_gray',img_cat_gray)\n",
    "plt.imshow(img)\n",
    "plt.imshow(img_cat_gray, cmap='gray')\n",
    "plt.show()\n",
    "if cv2.waitKey(0) & 0xFF==ord('q'): # wait for 'q' key to exit\n",
    "    cv2.destroyAllWindows()\n",
    "elif cv2.waitKey(0) & 0xFF==ord('s'): # wait for 's' key to save and exit\n",
    "    cv2.imwrite('./results/cats_color.png',img)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Resize/Rotate/Draw Function\n",
    "\n",
    "### â— Resize Img  \n",
    "\n",
    "To resize an image, scale it along each axis (height and width), considering the specified scale factors or just set the desired height and width.  \n",
    "\n",
    "When resizing an image:\n",
    "\n",
    "- It is important to keep in mind the original aspect ratio of the image (i.e. width by height), if you want to maintain the same in the resized image too.\n",
    "- Reducing the size of an image will require resampling of the pixels. \n",
    "- Increasing the size of an image requires reconstruction of the image. This means you need to interpolate new pixels.\n",
    "\n",
    "Various interpolation techniques come into play to accomplish these operations. Several methods are available in OpenCV, the choice typically depends on the particular application.  \n",
    "https://learnopencv.com/image-resizing-with-opencv/\n",
    "\n",
    "~ Syntax:\n",
    "\n",
    "> **cv2.resize(img, size,fx,fy,interpolation)**\n",
    "\n",
    "~ Parameters:\n",
    "\n",
    "- img â€“ input image (required).  \n",
    "- size â€“ desired size for the output image after resizing (required)  \n",
    "- fx â€“ Scale factor along the horizontal axis.(optional)  \n",
    "- fy â€“ Scale factor along the vertical axis.  \n",
    "- **Interpolation(optional)** : This flag uses following methods:   \n",
    ">- INTER_NEAREST â€“ a nearest-neighbor interpolation  \n",
    ">- INTER_LINEAR â€“ a bilinear interpolation (used by default)   \n",
    ">- INTER_AREA â€“ resampling using pixel area relation. When the image is zoomed, it is similar to the INTER_NEAREST.    \n",
    ">- INTER_CUBIC â€“ a bicubic interpolation over 4Ã—4 pixel neighborhood   \n",
    ">- INTER_LANCZOS4 â€“ a Lanczos interpolation over 8Ã—8 pixel neighborhood   \n",
    "\n",
    "* **INTER_CUBIC:** Mainly used when **increasing** the size.  \n",
    "* **INTER_AREA:** Mainly used when **making the size small.**\n",
    "\n",
    "<img src = './images/interpolation_ex.png' width=600 height=400>  \n",
    "\n",
    "> https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html?highlight=resize#resize\n",
    "\n",
    "~ Example:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2  \n",
    "\n",
    "img = cv2.imread('./images/dogs/04.jpg',1)   # using imread('path') and 1 denotes read as  color image  \n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_NEAREST=cv2.resize(img, (700, 700), interpolation = cv2.INTER_NEAREST) # enlarge compare\n",
    "img_CUBIC=cv2.resize(img, (700, 700), interpolation = cv2.INTER_CUBIC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(10, 10), dpi=80)\n",
    "plt.subplot(131),plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)),plt.title('original'),plt.axis('on')\n",
    "plt.subplot(132),plt.imshow(cv2.cvtColor(img_NEAREST, cv2.COLOR_BGR2RGB)),plt.title('img_NEAREST'),plt.axis('on')\n",
    "plt.subplot(133),plt.imshow(cv2.cvtColor(img_CUBIC, cv2.COLOR_BGR2RGB)),plt.title('img_CUBIC'),plt.axis('on')\n",
    "plt.show()\n",
    "# cv2.imshow(\"Resized\",img_resized)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_small = cv2.resize(img, (64,64))\n",
    "img_AREA = cv2.resize(img, (64,64), interpolation = cv2.INTER_AREA) # make small\n",
    "\n",
    "# cv2.imshow('Image resize', img_rs) # display img\n",
    "# cv2.waitKey(0) # 0: wait infinitely\n",
    "# cv2.destroyAllWindows()\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(10, 10), dpi=80)\n",
    "plt.subplot(131),plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)),plt.title('original'),plt.axis('on')\n",
    "plt.subplot(132),plt.imshow(cv2.cvtColor(img_small, cv2.COLOR_BGR2RGB)),plt.title('img_small_no_intpl'),plt.axis('on')\n",
    "plt.subplot(133),plt.imshow(cv2.cvtColor(img_AREA, cv2.COLOR_BGR2RGB)),plt.title('img_AREA'),plt.axis('on')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rs2 = cv2.resize(img, None,fx=0.5, fy=1.5)# fx=1.0, fy=0.5, fx=0.5,fy=2.0\n",
    "# cv2.imshow('Image Basic cv resize2', img_rs2) # display img\n",
    "plt.imshow(cv2.cvtColor(img_rs2, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cat = plt.imread('./images/cats/cat.jpg')\n",
    "img_dog = plt.imread('./images/dogs/01.jpg')\n",
    "print(img_cat.shape) # height x width\n",
    "plt.imshow(img_cat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cat_rs1=cv2.resize(img_cat,(100,200)) # width x height\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.imshow(img_cat_rs1), ax.axis('off'), ax.set_title('img_cat_rs1 img')\n",
    "plt.show()  \n",
    "img_cat_rs1.shape # 200 x 100 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Method to scaling\n",
    "img_cat_rs2 = cv2.resize(img_cat, None, fx=0.5, fy=0.5) # reduce size certain percentage\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.imshow(img_cat_rs2), ax.axis('off'), ax.set_title('img_cat_rs2 img')\n",
    "plt.show()  \n",
    "img_cat.shape,img_cat_rs2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â–  Upscaling Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cat_larger = cv2.resize(img_cat, (1000,1000))\n",
    "img_cat_CUBIC = cv2.resize(img_cat, (1000,1000),interpolation=cv2.INTER_CUBIC) # for inc size\n",
    "# print(img_cat_CUBIC.shape)\n",
    "\n",
    "figure(figsize=(10, 10), dpi=80)\n",
    "plt.subplot(131),plt.imshow(img_cat),plt.title('original'),plt.axis('on')\n",
    "plt.subplot(132),plt.imshow(img_cat_larger),plt.title('img_cat_larger'),plt.axis('on')\n",
    "plt.subplot(133),plt.imshow(img_cat_CUBIC),plt.title('img_cat_CUBIC'),plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â— Rotate Img\n",
    "\n",
    "We may need to rotate an image in some of the cases and we can do it easily by using OpenCV .\n",
    "We use cv2.rotate() method to rotate a 2D array in multiples of 90 degrees. \n",
    "\n",
    "~ Syntax:  \n",
    "> **cv2.rotate(img, rotateCode[, dst])**  \n",
    "\n",
    "~ Parameters:  \n",
    "    \n",
    ">- img: It is the image to be rotated.\n",
    ">- rotateCode: It is an enum to specify how to rotate the array.Here are some of the possible values :  \n",
    ">>- cv2.cv2.ROTATE_90_CLOCKWISE  \n",
    ">>- cv2.ROTATE_180  \n",
    ">>- cv2.ROTATE_90_COUNTERCLOCKWISE  \n",
    "\n",
    "~ Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mrotate(img, cv2\u001b[38;5;241m.\u001b[39mROTATE_90_COUNTERCLOCKWISE) \n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# cv2.imshow(\"Rotated\",image)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# cv2.waitKey()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# cv2.destroyAllWindows()\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "image = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE) \n",
    "# cv2.imshow(\"Rotated\",image)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if we want to rotate the image by a certain angle.We can use another method for that.First calculate the affine matrix that does the affine transformation (linear mapping of pixels) by using the getRotationMatrix2D method,next we warp the input image with the affine matrix using warpAffine method.\n",
    "\n",
    "~ syntax:\n",
    "\n",
    "> **cv2.getRotationMatrix2D(center, angle, scale)**  \n",
    "\n",
    "\n",
    "~ Parameters:  \n",
    "    \n",
    ">- center: center of the image (the point about which rotation has to happen)\n",
    "- angle: angle by which image has to be rotated in the anti-clockwise direction.\n",
    "- scale: scales the image by the value provided,1.0 means the shape is preserved.\n",
    "\n",
    "~ syntax:\n",
    "\n",
    "> **cv2.warpAffine(Img, M, (W, H))**  \n",
    "\n",
    "~ Parameters:  \n",
    ">- Img: image to be rotated.  \n",
    ">- M: affine matrix returned by cv2.getRotationMatrix2D\n",
    ">- H: height of image\n",
    ">- W: width of the image.\n",
    "\n",
    "\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the opencv module  \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_bgr = cv2.imread('./images/dogs/04.jpg',1)  \n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "(h, w) = img_rgb.shape[:2]\n",
    "center = (w / 2, h / 2) # calculate the center of the image\n",
    "scale = 1.0\n",
    "M = cv2.getRotationMatrix2D(center, 45, scale) # Perform the counter clockwise rotation holding at the center 45 degrees\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated45 = cv2.warpAffine(img_rgb, M, (h, w))\n",
    " \n",
    "# 110 degrees\n",
    "M = cv2.getRotationMatrix2D(center,110, scale)\n",
    "rotated110 = cv2.warpAffine(img_rgb, M, (w, h))\n",
    " \n",
    "# 150 degrees\n",
    "M = cv2.getRotationMatrix2D(center, 150, scale)\n",
    "rotated150 = cv2.warpAffine(img_rgb, M, (h, w))\n",
    "\n",
    "fig, axs = plt.subplots(1,4,figsize=(15,10))\n",
    "axs[0].imshow(img_rgb), axs[0].axis('off'), axs[0].set_title('Original Image')\n",
    "axs[1].imshow(rotated45), axs[1].axis('off'), axs[1].set_title('rotated by 45 dg')\n",
    "axs[2].imshow(rotated110), axs[2].axis('off'), axs[2].set_title(' by 110 dg')\n",
    "axs[3].imshow(rotated150), axs[3].axis('off'), axs[3].set_title(' by 150 dg')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# cv2.imshow('Original Image',img_bgr)\n",
    "# cv2.imshow('Image rotated by 45 degrees',rotated45) \n",
    "# cv2.imshow('Image rotated by 110 degrees',rotated110) \n",
    "# cv2.imshow('Image rotated by 150 degrees',rotated150)\n",
    "# cv2.waitKey(0) # waits until a key is pressed\n",
    "# cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Flipping an image  \n",
    "\n",
    "We can flip the image across the x-axis, the y-axis and then across both axes.\n",
    "\n",
    "~ Syntax:   \n",
    "- **cv2.cv.flip(src, flipCode[, dst] )**  \n",
    "\n",
    "~ Parameters:   \n",
    "- src: Input array.\n",
    "- dst: Output array of the same size and type as src.\n",
    "- flip code: A flag to specify how to flip the array;  \n",
    ">- 0 means flipping around the x-axis \n",
    ">- positive value (for example, 1) means flipping around y-axis.   \n",
    ">- Negative value (for example, -1) means flipping around both axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "  \n",
    "img_org = cv2.imread('./images/practice_img/motorcycle.jpg')\n",
    "  \n",
    "flipVertical = cv2.flip(img_org, 0)\n",
    "flipHorizontal = cv2.flip(img_org, 1)\n",
    "flipBoth = cv2.flip(img_org, -1)\n",
    " \n",
    "cv2.imshow('Original image', img_org)\n",
    "cv2.imshow('Flipped vertical image', flipVertical)\n",
    "cv2.imshow('Flipped horizontal image', flipHorizontal)\n",
    "cv2.imshow('Flipped both image', flipBoth)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "plt.subplot(141),plt.imshow(cv2.cvtColor(img_org, cv2.COLOR_BGR2RGB)),plt.title('original'),plt.axis('off')\n",
    "plt.subplot(142),plt.imshow(cv2.cvtColor(flipVertical, cv2.COLOR_BGR2RGB)),plt.title('flipVertical'),plt.axis('off')\n",
    "plt.subplot(143),plt.imshow(cv2.cvtColor(flipHorizontal, cv2.COLOR_BGR2RGB)),plt.title('flipHorizontal'),plt.axis('off')\n",
    "plt.subplot(144),plt.imshow(cv2.cvtColor(flipBoth, cv2.COLOR_BGR2RGB)),plt.title('flipBoth'),plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â— Drawing Functions\n",
    "We may require to draw certain shapes on an image such as circle, rectangle, ellipse, polylines, convex, etc. and we can easily do this using OpenCV. It is often used when we want to highlight any object in the input image for example in case of face detection, we might want to highlight the face with a rectangle. Here we will learn about the drawing functions such as circle, rectangle, lines, polylines and also see how to write text on an image.\n",
    "\n",
    "#### â–  Drawing circle:\n",
    "\n",
    "~ Syntax:\n",
    "> **cv2.circle(image, center_coordinates, radius, color, thickness)**\n",
    "\n",
    "~ Parameters: \n",
    ">- image â€“ It is the input image on which a circle is to be drawn.   \n",
    ">- center_coordinates â€“ It is the center coordinates of the circle. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value).   \n",
    ">- radius â€“ It is the radius of the circle.   \n",
    ">- color â€“ It is the color of the border line of the circle to be drawn. We can pass a tuple For in BGR,  eg: (255, 0, 0) for blue color.    \n",
    ">- thickness â€“ It is the thickness of the circle border line in px. Thickness of -1 px will fill the circle shape by the specified color.  \n",
    ">- Return Value â€“ It returns an image.\n",
    "\n",
    "~ Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = np.full((400, 400, 3), 255, np.uint8)\n",
    "image = cv2.circle(image, (150, 150), 80, (0, 0,255), -1)\n",
    "image = cv2.circle(image, (300, 300), 80, (0, 255,255), 3)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./images/park.jpg',1)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.circle(img,(200,300), 50, (255,0,0), -1)  \n",
    "# cv2.imshow('image',img)  \n",
    "# cv2.waitKey(0)  \n",
    "# cv2.destroyAllWindows() \n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/park.jpg',1)\n",
    "image_plt_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "cv2.circle(image_plt_rgb,(200,300), 50, (0,0,255), -1)  \n",
    "\n",
    "plt.imshow(image_plt_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "canvas = np.zeros((300, 300, 3), dtype = \"uint8\")\n",
    "centerX, centerY = (canvas.shape[1] // 2, canvas.shape[0] // 2)\n",
    "white = (255, 255, 255)\n",
    "\n",
    "for r in range(0, 175, 25):\n",
    "    cv2.circle(canvas, (centerX, centerY), r, white)\n",
    "#     cv2.imshow(\"Canvas\", canvas)\n",
    "    plt.imshow(canvas)\n",
    "    \n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 25):\n",
    "    radius = np.random.randint(5, high = 200)\n",
    "    color = np.random.randint(0, high = 256, size = (3,)).tolist()\n",
    "    pt = np.random.randint(0, high = 300, size = (2,))\n",
    "    cv2.circle(canvas, tuple(pt), radius, color, -1)\n",
    "#     cv2.imshow(\"Canvas\", canvas)\n",
    "    plt.imshow(canvas)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â» Practice draw circle (do it yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_circle pt\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('./images/blank_500.jpg')\n",
    "\n",
    "cv2.circle(img, (150, 150), 100, (255,0,0))     # center(150,150), radius 100 \n",
    "cv2.circle(img, (300, 150), 70, (0,255,0), 5)   # center(300,150), radius  70 \n",
    "cv2.circle(img, (400, 150), 50, (0,0,255), -1)  # center(400,150), radius  50, fill \n",
    "\n",
    "cv2.ellipse(img, (50, 300), (50, 50), 0, 0, 360, (0,0,255))    # center(50,300), radius (50), rotate 0, 0 to 360 \n",
    "cv2.ellipse(img, (150, 300), (50, 50), 0, 0, 180, (255,0,0))    # center(150, 300), lower half circle\n",
    "cv2.ellipse(img, (200, 300), (50, 50), 0, 181, 360, (0,0,255))    #center(200, 300), upper half circle \n",
    "\n",
    "cv2.ellipse(img, (325, 300), (75, 50), 0, 0, 360, (0,255,0))    # center(325, 300), radius (75,50) flat  \n",
    "cv2.ellipse(img, (450, 300), (50, 75), 0, 0, 360, (255,0,255))    # center(450,300), radius (50,75) skinny \n",
    "cv2.ellipse(img, (50, 425), (50, 75), 15, 0, 360, (0,0,0))    # center(50, 425), radius (50,75), rotate 15 \n",
    "cv2.ellipse(img, (200, 425), (50, 75), 45, 0, 360, (0,0,0))    # center(200,425), radius (50,75), rotate 45\n",
    "\n",
    "cv2.ellipse(img, (350, 425), (50, 75), 45, 0, 180, (0,0,255))    # center(350,425), Draw a lower semicircle after a 45-degree rotation of the ellipse \n",
    "cv2.ellipse(img, (400, 425), (50, 75), 45, 181, 360, (255,0,0))    # center(400,425), Draw a upper semicircle after a 45-degree rotation of the ellipse \n",
    "\n",
    "cv2.imshow('circle', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â» Drawing Random Circles Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 200\n",
    "width = 400\n",
    "NUMBER = 100\n",
    "lineType = cv.LINE_8 \n",
    "x1, x2, y1, y2 = -width/2, width*3/2, -height/2, height*3/2\n",
    "\n",
    "def circles():\n",
    "    wndname = \"Drawing Circles Demo\"\n",
    "\n",
    "    for i in range(NUMBER):\n",
    "        center = []\n",
    "        center.append(np.random.randint(x1, x2))\n",
    "        center.append(np.random.randint(x1, x2))\n",
    "        color = \"%06x\" % np.random.randint(0, 0xFFFFFF)\n",
    "        color = tuple(int(color[i:i+2], 16) for i in (0, 2 ,4))\n",
    "        cv.circle(image, tuple(center), np.random.randint(0, 300), color, np.random.randint(-1, 9), lineType)\n",
    "#         cv.imshow(wndname, image)\n",
    "#         if cv.waitKey(DELAY) >= 0:\n",
    "    plt.imshow(image), plt.title(wndname)\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "image = np.zeros((height, width, 3), dtype = np.uint8)\n",
    "circles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â–  Drawing Rectangle\n",
    "\n",
    "In a similar way we can draw a rectangle. \n",
    "\n",
    "~ Syntax:\n",
    "\n",
    "> **cv2.rectangle(image, start_point, end_point, color, thickness)**\n",
    "\n",
    "~ Parameters: \n",
    "\n",
    ">- image â€“ It is the input image on which rectangle is to be drawn.\n",
    "- start_point â€“ It is the starting coordinates(top left vertex) of the rectangle. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value).\n",
    "- end_point â€“ It is the ending coordinates(bottom right) of the rectangle. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value).\n",
    "- color â€“ It is the color of the border line of the rectangle to be drawn. We can pass a tuple For in BGR,  eg: (255, 0, 0) for blue color. \n",
    "- thickness â€“ It is the thickness of the rectangle border line in px. Thickness of -1 px will fill the rectangle shape by the specified color.\n",
    "- Return Value â€“ It returns an image.\n",
    "\n",
    "~ Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "img = cv2.imread('./images/park.jpg',1)\n",
    "img.shape\n",
    "\n",
    "cv2.rectangle(img,(15,25),(200,150),(0,255,255),15)  \n",
    "# cv2.imshow('image',img)  \n",
    "# cv2.waitKey(0)  \n",
    "# cv2.destroyAllWindows() \n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â» Practice draw rectangle (do it yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw rectangle pt\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('./images/blank_500.jpg')\n",
    "\n",
    "cv2.rectangle(img, (50, 50), (150, 150), (255,0,0) )        # left top, right bottom\n",
    "cv2.rectangle(img, (300, 300), (100, 100), (0,255,0), 10 )  \n",
    "cv2.rectangle(img, (450, 200), (200, 450), (0,0,255), -1 )  \n",
    "\n",
    "cv2.imshow('rectangle', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(img), plt.title('Rectangles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â» Drawing Random Rectangles Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectangle():\n",
    "    wndname = \"Drawing Random Rectangles Demo\"    \n",
    "    for i in range(NUMBER*2):\n",
    "        pt1, pt2 = [], []\n",
    "        pt1.append(np.random.randint(x1, x2))\n",
    "        pt1.append(np.random.randint(y1, y2))\n",
    "        pt2.append(np.random.randint(x1, x2))\n",
    "        pt2.append(np.random.randint(y1, y2))\n",
    "        color = \"%06x\" % np.random.randint(0, 0xFFFFFF)\n",
    "        color = tuple(int(color[i:i+2], 16) for i in (0, 2 ,4))\n",
    "        thickness = np.random.randint(-3, 10)\n",
    "        marker = np.random.randint(0, 10)\n",
    "        marker_size = np.random.randint(30, 80)\n",
    "\n",
    "        if (marker > 5):\n",
    "            cv.rectangle(image, tuple(pt1), tuple(pt2), color, max(thickness, -1), lineType)\n",
    "        else:\n",
    "            cv.drawMarker(image, tuple(pt1), color, marker, marker_size)\n",
    "#         cv.imshow(wndname, image)\n",
    "#         if cv.waitKey(DELAY)>=0:\n",
    "    plt.imshow(image),plt.title(wndname)\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "height = 200\n",
    "width = 400\n",
    "NUMBER = 100\n",
    "lineType = cv.LINE_8 \n",
    "x1, x2, y1, y2 = -width/2, width*3/2, -height/2, height*3/2\n",
    "\n",
    "image = np.zeros((height, width, 3), dtype = np.uint8)\n",
    "rectangle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â–  Drawing Lines\n",
    "\n",
    "##### â€¢ Line Types  \n",
    "\n",
    "- Bresenham's algorithm: An algorithm developed to draw lines only with integer operations without real operations,\n",
    ">- Four-point neighborhood connection: When assigning pixels to a segment, consider only the right, left, top, and bottom areas to be assigned to the next location.    \n",
    ">- Eight-point neighborhood connection: Diagonal directions are also added, taking into account a total of eight positions            \n",
    ">- Anti-Aliasing: to eliminate staircase at the edge of an image or object and make the staircase look smoother.    \n",
    ">- It uses Gaussian filtering, and for wide lines, the ends are always rounded.            \n",
    "\n",
    "##### â€¢ Bit Shift  \n",
    "            \n",
    "- You can also use the figure drawing function with real-value coordinates that contain values to the decimal point.    \n",
    "\n",
    "\n",
    "~ Syntax: \n",
    "\n",
    "> **cv2.line(image, start_point, end_point, color, thickness, lineType)**\n",
    "\n",
    "~ Parameters:  \n",
    ">- image: It is the input image on which line is to be drawn.\n",
    "- start_point: It is the starting coordinates of the line. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value).\n",
    "- end_point: It is the ending coordinates of the line. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value).\n",
    "- color: It is the color of the line to be drawn. We can pass a tuple For in BGR,  eg: (255, 0, 0) for blue color. \n",
    "- thickness: It is the thickness of the line in px.(default=1)  \n",
    "- lineType: cv2.LINE_4, cv2.LINE_8, cv2.LINE_AA...\n",
    "\n",
    "~ Note: color type is BGR not RGB     \n",
    "\n",
    "### ðŸ‘‰ Line Type  \n",
    "\n",
    "Command      |     Function   \n",
    "-------------|--------------\n",
    "cv2.FILLED   |Fill\n",
    "cv2.LINE_4   |Four-point neighborhood connection\n",
    "cv2.LINE_8   |Eight-point neighborhood connection\n",
    "cv2.LINE_AA  |AntiAlias        \n",
    "    \n",
    "~ Example:    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "img = cv2.imread('./images/son/son3.jpg', -1) \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining points for polylines  \n",
    "cv2.line(img, (100, 50), (300,400), (0,255,255), 3) \n",
    "cv2.arrowedLine(img, (900, 350), (600,400), (0,255,255), 5) \n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â» Practice draw line (do it yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_line pt\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/blank_500.jpg')\n",
    "\n",
    "cv2.line(img, (50, 50), (150, 50), (255,0,0))   # blue 1pxl\n",
    "cv2.line(img, (200, 50), (300, 50), (0,255,0))  # green 1pxl\n",
    "cv2.line(img, (350, 50), (450, 50), (0,0,255))  # red 1pxl\n",
    "# img = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "cv2.arrowedLine(img, (100, 100), (250, 100), color=(255, 0, 0), thickness=2) # arrowed Line\n",
    "\n",
    "cv2.imshow('lines', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10pxl      \n",
    "cv2.line(img, (100, 100), (400, 100), (255,255,0), 10) # sky blue         \n",
    "cv2.line(img, (100, 150), (400, 150), (255,0,255), 10)  # (blue+red)    \n",
    "cv2.line(img, (100, 200), (400, 200), (0,255,255), 10)  # yellow 10pxl          \n",
    "cv2.line(img, (100, 250), (400, 250), (200,200,200), 10) # gray     \n",
    "cv2.arrowedLine(img, (100, 300), (400, 300), (0,0,0), 10)  # black                  \n",
    "cv2.imshow('lines', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(img), plt.title('Lines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.line(img, (100, 350), (400, 400), (0,0,255), 20, cv2.LINE_4) # pxl broken \n",
    "cv2.line(img, (100, 400), (400, 450), (0,0,255), 20, cv2.LINE_8) # pxl broken  \n",
    "cv2.line(img, (100, 450), (400, 500), (0,0,255), 20, cv2.LINE_AA) # Anti-Aliasing Line  \n",
    "cv2.line(img, (0,0), (500,500), (0,0,255)) # Diagonal throughout the image                    \n",
    "\n",
    "cv2.imshow('lines', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(img), plt.title('Lines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â» Drawing Random Lines Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_lines():\n",
    "    wndname = \"Drawing Random Lines Demo\"\n",
    "    for i in range(NUMBER*2):\n",
    "        pt1, pt2 = [], []\n",
    "        pt1.append(np.random.randint(x1, x2))\n",
    "        pt1.append(np.random.randint(y1, y2))\n",
    "        pt2.append(np.random.randint(x1, x2))\n",
    "        pt2.append(np.random.randint(y1, y2))\n",
    "        color = \"%06x\" % np.random.randint(0, 0xFFFFFF)\n",
    "        color = tuple(int(color[i:i+2], 16) for i in (0, 2 ,4))\n",
    "        arrowed =  np.random.randint(0, 6)\n",
    "        if (arrowed<3):\n",
    "            cv.line(image, tuple(pt1), tuple(pt2), color, np.random.randint(1, 10), lineType)\n",
    "        else:\n",
    "            cv.arrowedLine(image, tuple(pt1), tuple(pt2), color, np.random.randint(1, 10), lineType)\n",
    "#         cv.imshow(wndname, image)\n",
    "#         if cv.waitKey(DELAY)>=0:\n",
    "    plt.imshow(image),plt.title(wndname)\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "\n",
    "height = 200\n",
    "width = 400\n",
    "NUMBER = 100\n",
    "lineType = cv.LINE_AA \n",
    "x1, x2, y1, y2 = -width/2, width*3/2, -height/2, height*3/2\n",
    "\n",
    "image = np.zeros((height, width, 3), dtype = np.uint8)\n",
    "random_lines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â–  Drawing Polylines\n",
    "\n",
    "~ Syntax:\n",
    "\n",
    "> **cv2.polyLine(image, arr, is_closed, color, thickness)**  \n",
    "\n",
    "~ Parameters:\n",
    "\n",
    ">- img â€“ It represents an image.\n",
    "- arr -represents the coordinates of vertices into an array of shape nx1x2 where n is number of vertices and it should be of type int32.\n",
    "- is_Closed â€“ It is a flag that indicates whether the drawn polylines are closed or not.\n",
    "- color â€“ Color of polylines. We can pass a tuple For in BGR,  eg: (255, 0, 0) for blue color. \n",
    "- thickness â€“ It represents the Thickness of the polylineâ€™s edges.  \n",
    "\n",
    "~ Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/son/son3.jpg', -1) \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining points for polylines  \n",
    "pts = np.array([[100,50],[200,300],[700,200],[500,100]], np.int32)  \n",
    "cv2.polylines(img, [pts], True, (0,255,255), 3)  \n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â» Practice draw polylines (do it yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw polylines pt\n",
    "import cv2\n",
    "import numpy as np                          \n",
    "\n",
    "img = cv2.imread('./images/blank_500.jpg')\n",
    "\n",
    "pts1 = np.array([[50,50], [150,150], [100,140],[200,240]], dtype=np.int32) # thunder line\n",
    "pts2 = np.array([[350,50], [250,200], [450,200]], dtype=np.int32) # triangle\n",
    "pts3 = np.array([[150,300], [50,450], [250,450]], dtype=np.int32) # triangle\n",
    "pts4 = np.array([[350,250], [450,350], [400,450],[300,450], [250,350]], dtype=np.int32) # 5 \n",
    "\n",
    "cv2.polylines(img, [pts1], False, (255,0,0))                    \n",
    "cv2.polylines(img, [pts2], False, (0,0,0), 10)                  \n",
    "cv2.polylines(img, [pts3], True, (0,0,255), 10)                 \n",
    "cv2.polylines(img, [pts4], True, (0,0,0))                      \n",
    "\n",
    "cv2.imshow('polyline', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(img), plt.title('Polylines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Drawing Polygonal Curves\n",
    "\n",
    "cv2.polylines(image, points, is_closed, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.full((512, 512, 3), 255, np.uint8)\n",
    "points = np.array([[50, 50], [150, 350], [450, 450], [300, 200]])\n",
    "image = cv2.polylines(image, [points], True, (255, 0, 255), 4)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â» Drawing Polygonal Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygonal():\n",
    "    wndname = \"Drawing polygonal Demo\"\n",
    "\n",
    "    for i in range(NUMBER):\n",
    "        pt = [(0, 0)]*6\n",
    "        pt = np.resize(pt, (2, 3, 2))\n",
    "        pt[0][0][0] = np.random.randint(x1, x2)\n",
    "        pt[0][0][1] = np.random.randint(y1, y2)\n",
    "        pt[0][1][0] = np.random.randint(x1, x2)\n",
    "        pt[0][1][1] = np.random.randint(y1, y2)\n",
    "        pt[0][2][0] = np.random.randint(x1, x2)\n",
    "        pt[0][2][1] = np.random.randint(y1, y2)\n",
    "        pt[1][0][0] = np.random.randint(x1, x2)\n",
    "        pt[1][0][1] = np.random.randint(y1, y2)\n",
    "        pt[1][1][0] = np.random.randint(x1, x2)\n",
    "        pt[1][1][1] = np.random.randint(y1, y2)\n",
    "        pt[1][2][0] = np.random.randint(x1, x2)\n",
    "        pt[1][2][1] = np.random.randint(y1, y2)\n",
    "        color = \"%06x\" % np.random.randint(0, 0xFFFFFF)\n",
    "        color = tuple(int(color[i:i+2], 16) for i in (0, 2 ,4))\n",
    "        alist = []\n",
    "        for k in pt[0]:\n",
    "            alist.append(k)\n",
    "        for k in pt[1]:\n",
    "            alist.append(k)\n",
    "        ppt = np.array(alist)\n",
    "        cv.polylines(image, [ppt], True, color, thickness = np.random.randint(1, 10), lineType = lineType)\n",
    "#         cv.imshow(wndname, image)\n",
    "#         if cv.waitKey(DELAY) >= 0:\n",
    "    plt.imshow(image), plt.title(wndname)\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "height = 200\n",
    "width = 400\n",
    "NUMBER = 100\n",
    "lineType = cv.LINE_AA \n",
    "x1, x2, y1, y2 = -width/2, width*3/2, -height/2, height*3/2\n",
    "\n",
    "image = np.zeros((height, width, 3), dtype = np.uint8)\n",
    "polygonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## â–¶ Drawing fill Demo : fills an area bounded by several polygonal contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill():\n",
    "    wndname = \"Drawing fill Demo\"\n",
    "\n",
    "    for i in range(NUMBER):\n",
    "        pt = [(0, 0)]*6\n",
    "        pt = np.resize(pt, (2, 3, 2))\n",
    "        pt[0][0][0] = np.random.randint(x1, x2)\n",
    "        pt[0][0][1] = np.random.randint(y1, y2)\n",
    "        pt[0][1][0] = np.random.randint(x1, x2)\n",
    "        pt[0][1][1] = np.random.randint(y1, y2)\n",
    "        pt[0][2][0] = np.random.randint(x1, x2)\n",
    "        pt[0][2][1] = np.random.randint(y1, y2)\n",
    "        pt[1][0][0] = np.random.randint(x1, x2)\n",
    "        pt[1][0][1] = np.random.randint(y1, y2)\n",
    "        pt[1][1][0] = np.random.randint(x1, x2)\n",
    "        pt[1][1][1] = np.random.randint(y1, y2)\n",
    "        pt[1][2][0] = np.random.randint(x1, x2)\n",
    "        pt[1][2][1] = np.random.randint(y1, y2)\n",
    "        color = \"%06x\" % np.random.randint(0, 0xFFFFFF)\n",
    "        color = tuple(int(color[i:i+2], 16) for i in (0, 2 ,4))\n",
    "        alist = []\n",
    "        for k in pt[0]:\n",
    "            alist.append(k)\n",
    "        for k in pt[1]:\n",
    "            alist.append(k)\n",
    "        ppt = np.array(alist)\n",
    "        cv.fillPoly(image, [ppt], color, lineType)\n",
    "#         cv.imshow(wndname, image)\n",
    "#         if cv.waitKey(DELAY) >= 0:\n",
    "    plt.imshow(image), plt.title(wndname)\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "height = 200\n",
    "width = 400\n",
    "NUMBER = 100\n",
    "lineType = cv.LINE_AA \n",
    "x1, x2, y1, y2 = -width/2, width*3/2, -height/2, height*3/2\n",
    "\n",
    "image = np.zeros((height, width, 3), dtype = np.uint8)\n",
    "fill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Drawing ellipse  \n",
    "\n",
    "cv2.ellipse() method is used to draw a ellipse on any image.  \n",
    "\n",
    "~ Syntax: \n",
    "- **cv2.ellipse(image, centerCoordinates, axesLength, angle, startAngle, endAngle, color [, thickness[, lineType[, shift]]])** \n",
    "\n",
    "~ Parameters:     \n",
    "- img, color, thickness, lineType: same\n",
    "- centerCoordinates: It is the center coordinates of ellipse. The coordinates are represented as tuples of two values i.e. (x,y).  \n",
    "- axesLength: It contains tuple of two variables containing major and minor axis of ellipse (major axis length, minor axis length).  \n",
    "- angle: Ellipse rotation angle in degrees.\n",
    "- startAngle: Starting angle of the elliptic arc in degrees.\n",
    "- endAngle: Ending angle of the elliptic arc in degrees.\n",
    "- shift: This is an optional parameter. It denotes the number of fractional bits in the coordinates of the center and values of axes.\n",
    "\n",
    "~ Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_ellipse\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('./images/blank_500.jpg')\n",
    "\n",
    "cv2.ellipse(img, (50, 300), (50, 50), 0, 0, 360, (0,0,255)) # center(50,300), radius(50), from 0,0 angle to 360   \n",
    "cv2.ellipse(img, (150, 300), (50, 50), 0, 0, 180, (255,0,0),3) # center(150, 300), radius(50), from 0,0 angle to 180 below half circle   \n",
    "cv2.ellipse(img, (200, 300), (50, 50), 0, 181, 360, (0,0,255),5) #center(200, 300), radius(50),from 0,181 angle to 360 upper half circle   \n",
    "cv2.imshow('ellipse_ex1', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.ellipse() method \n",
    "import cv2 \n",
    "    \n",
    "img0 = cv2.imread('./images/son/son4.jpg', -1) \n",
    "\n",
    "center_coordinates = (260, 170)\n",
    "axesLength = (100, 50)\n",
    "angle = 0\n",
    "startAngle = 0\n",
    "endAngle = 360\n",
    "color = (0, 0, 255) # Red color in BGR\n",
    "thickness = 5 # Line thickness of 5 px\n",
    "   \n",
    "# Using cv2.ellipse() method, Draw a ellipse with red line borders of thickness of 5 px\n",
    "image = cv2.ellipse(img0, center_coordinates, axesLength,angle, startAngle, endAngle, color, thickness)\n",
    "   \n",
    "cv2.imshow('Ellipse', img0) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using thickness of -1 px(fill) and rotation of 30 degrees.\n",
    "import cv2\n",
    "    \n",
    "img2 = cv2.imread('./images/son/son4.jpg', -1) \n",
    "\n",
    "img2 = cv2.ellipse(img2, (290, 300), (100, 50), 30, 0, 360, (255, 0, 0), -1)\n",
    "\n",
    "cv2.imshow('Fill Ellipse', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "img0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(8,8))\n",
    "axs[0].imshow(img0), axs[0].axis('on'), axs[0].set_title('Ellipse')\n",
    "axs[1].imshow(img2), axs[1].axis('on'), axs[1].set_title('Fill Ellipse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â» Practice draw ellipse (do it yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_ellipse pt\n",
    "import cv2\n",
    "\n",
    "img_2 = cv2.imread('./images/blank_500.jpg')\n",
    "\n",
    "cv2.ellipse(img_2, (325, 300), (75, 50), 0, 0, 360, (0,255,0),1)  # center(325, 300), radius(75,50) flat \n",
    "cv2.ellipse(img_2, (450, 300), (50, 75), 0, 0, 360, (255,0,255),3) # center(450,300), radius(50,75) skinny   \n",
    "cv2.ellipse(img_2, (50, 425), (50, 75), 15, 0, 360, (0,255,255),5) # center(50, 425), radius(50,75), rotate 15   \n",
    "cv2.ellipse(img_2, (200, 425), (50, 75), 45, 0, 360, (0,0,0),7) # center(200,425), radius(50,75), rotate 45   \n",
    "cv2.ellipse(img_2, (350, 425), (50, 75), 45, 0, 180, (0,0,255),9) # center(350,425), skinny below half,rotate 45   \n",
    "cv2.ellipse(img_2, (400, 425), (50, 75), 45, 181, 360, (255,0,0),11) # center(400,425), skinny upper half, rotate 45   \n",
    "\n",
    "cv2.imshow('ellipse_ex2', img_2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(10,10))\n",
    "axs[0].imshow(img), axs[0].axis('on'), axs[0].set_title('ellipse_ex1')\n",
    "axs[1].imshow(img_2), axs[1].axis('on'), axs[1].set_title('ellipse_ex2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â» Drawing Random Ellipse Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse():\n",
    "    wndname = \"Drawing Random Ellipse Demo\"\n",
    "\n",
    "    for i in range(NUMBER*2):\n",
    "        center = []\n",
    "        center.append(np.random.randint(x1, x2))\n",
    "        center.append(np.random.randint(x1, x2))\n",
    "        axes = []\n",
    "        axes.append(np.random.randint(0, 200))\n",
    "        axes.append(np.random.randint(0, 200))\n",
    "        angle = np.random.randint(0, 180)\n",
    "        color = \"%06x\" % np.random.randint(0, 0xFFFFFF)\n",
    "        color = tuple(int(color[i:i+2], 16) for i in (0, 2 ,4))\n",
    "        thickness = np.random.randint(-1, 9)\n",
    "        cv.ellipse(image, tuple(center), tuple(axes), angle, angle-100, angle + 200, color, thickness, lineType)\n",
    "#         cv.imshow(wndname, image)\n",
    "#         if cv.waitKey(DELAY)>=0:\n",
    "    plt.imshow(image), plt.title(wndname)\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "height = 200\n",
    "width = 400\n",
    "NUMBER = 100\n",
    "lineType = cv.LINE_AA \n",
    "x1, x2, y1, y2 = -width/2, width*3/2, -height/2, height*3/2\n",
    "\n",
    "image = np.zeros((height, width, 3), dtype = np.uint8)\n",
    "ellipse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â–  Write text on an image\n",
    "\n",
    "~ Syntax:  \n",
    "\n",
    ">**cv2.putText(img, text, org, font,fontScale color)**\n",
    "\n",
    "~ Parameters:\n",
    ">- img: It represents the input image on which we have to write text\n",
    "- text: The text which we want to write on the image.\n",
    "- org: It denotes the Bottom-left corner of the text string on the image. So it is used to set the location of text on the image\n",
    "- font: the font of text. Here is the list of supported fonts.\n",
    "- fontScale: The scale of the font by which you can increase or decrease size\n",
    "- color: Represents the color. We can pass a tuple For in BGR,  eg: (255, 0, 0) for blue color. \n",
    "\n",
    "### ðŸ‘‰ Font Type  \n",
    "Type      |Function         |Ref  \n",
    "-----------|------------|-----------\n",
    "cv2.FONT_HERSHEY_SIMPLEX = 0 |Normal size sans-serif fonts|-\n",
    "cv2.FONT_HERSHEY_PLAIN = 1 |Small size sans-serif fonts|-\n",
    "cv2.FONT_HERSHEY_DUPLEX = 2 |Normal size sans-serif fonts|sophisticated \n",
    "cv2.FONT_HERSHEY_COMPLEX = 3 |Normal size serif fonts|-\n",
    "cv2.FONT_HERSHEY_TRIPLEX = 4 |Normal size serif fonts|sophisticated \n",
    "cv2.FONT_HERSHEY_COMPLEX_SMALL = 5 |Small size handwritten fonts|-\n",
    "cv2.FONT_HERSHEY_SCRIPT_SIMPLEX = 6 |Normal size handwritten fonts|-\n",
    "cv2.FONT_HERSHEY_SCRIPT_COMPLEX = 7 |Normal size handwritten fonts|sophisticated \n",
    "cv2.FONT_ITALIC = 1 6|italics|-    \n",
    "\n",
    "âž¡ï¸ FONT_ITALIC is not a font, but is a flag that can be combined with the other fonts to get italic text.  \n",
    "    \n",
    "~ Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.full((400, 400, 3), 255, np.uint8)\n",
    "image = cv2.putText(image, 'Hello SSU!!', (10, 200), cv.FONT_HERSHEY_COMPLEX, 2,(255, 0, 0), 3, cv.LINE_AA)\n",
    "# cv.FONT_HERSHEY_COMPLEX, 3, 5\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX  \n",
    "img = cv2.imread('./images/son/son4.jpg', -1) \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cv2.putText(img,'Son, You rock!(u are amazing!)' ,(10,350), font, 1,(0,255,0),2)  \n",
    "#Display the image  \n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â» Practice write text (do it yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write text pt\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('./images/blank_500.jpg')\n",
    "\n",
    "\n",
    "cv2.putText(img, \"Plain\", (50, 30), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0,0))            # sans-serif small\n",
    "cv2.putText(img, \"Simplex\", (50, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0,0))        # sans-serif normal\n",
    "cv2.putText(img, \"Duplex\", (50, 110), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0,0))         # sans-serif bold\n",
    "cv2.putText(img, \"Simplex\", (200, 110), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,250)) # sans-serif normall X2  ---â‘ \n",
    "\n",
    "cv2.putText(img, \"Complex Small\", (50, 180), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0,0))   # serif small\n",
    "cv2.putText(img, \"Complex\", (50, 220), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0,0))               # serif normal\n",
    "cv2.putText(img, \"Triplex\", (50, 260), cv2.FONT_HERSHEY_TRIPLEX, 1, (0, 0,0))               # serif bold\n",
    "cv2.putText(img, \"Complex\", (200, 260), cv2.FONT_HERSHEY_TRIPLEX, 2, (0,0,255))               # serif normal X2  ---â‘¡\n",
    "\n",
    "cv2.putText(img, \"Script Simplex\", (50, 330), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (0, 0,0)) # hand-wringing sans-serif\n",
    "cv2.putText(img, \"Script Complex\", (50, 370), cv2.FONT_HERSHEY_SCRIPT_COMPLEX, 1, (0, 0,0)) # hand-wringing serif\n",
    "\n",
    "cv2.putText(img, \"Plain Italic\", (50, 430), cv2.FONT_HERSHEY_PLAIN | cv2.FONT_ITALIC, 1, (0, 0,0)) # sans-serif + italic ---â‘¢\n",
    "cv2.putText(img, \"Complex Italic\", (50, 470), cv2.FONT_HERSHEY_COMPLEX | cv2.FONT_ITALIC, 1, (0, 0,0)) # sarif + italic\n",
    "\n",
    "cv2.imshow('draw text', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(img), plt.title('draw text')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â» Drawing String Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string():\n",
    "    wndname = \"Drawing String Demo\"\n",
    "    \n",
    "    for i in range(NUMBER):\n",
    "        org = []\n",
    "        org.append(np.random.randint(x1, x2))\n",
    "        org.append(np.random.randint(x1, x2))\n",
    "        color = \"%06x\" % np.random.randint(0, 0xFFFFFF)\n",
    "        color = tuple(int(color[i:i+2], 16) for i in (0, 2 ,4))\n",
    "        cv.putText(image, \"Testing text rendering\", tuple(org), np.random.randint(0, 8), np.random.randint(0, 100)*0.05+0.1, color, np.random.randint(1, 10), lineType)\n",
    "#         cv.imshow(wndname, image)\n",
    "#         if cv.waitKey(DELAY) >= 0:\n",
    "    plt.imshow(image), plt.title(wndname)\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "height = 200\n",
    "width = 400\n",
    "NUMBER = 100\n",
    "lineType = cv.LINE_AA \n",
    "x1, x2, y1, y2 = -width/2, width*3/2, -height/2, height*3/2\n",
    "\n",
    "image = np.zeros((height, width, 3), dtype = np.uint8)\n",
    "string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2():\n",
    "    wndname = \"Drawing String2 Demo\"\n",
    "\n",
    "    textsize = cv.getTextSize(\"OpenCV forever!\", cv.FONT_HERSHEY_COMPLEX, 3, 5)\n",
    "    org = (int((width - textsize[0][0])/2), int((height - textsize[0][1])/2))\n",
    "    for i in range(0, 255, 2):\n",
    "        image2 = np.array(image) - i\n",
    "        cv.putText(image2, \"OpenCV forever!\", org, cv.FONT_HERSHEY_COMPLEX, 3, (i, i, 255), 5, lineType)\n",
    "#         cv.imshow(wndname, image2)\n",
    "#         if cv.waitKey(DELAY) >= 0:\n",
    "    plt.imshow(image2), plt.title(wndname)\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "height = 400\n",
    "width = 1000\n",
    "NUMBER = 100\n",
    "lineType = cv.LINE_AA \n",
    "x1, x2, y1, y2 = -width/2, width*3/2, -height/2, height*3/2\n",
    "\n",
    "image = np.zeros((height, width, 3), dtype = np.uint8)\n",
    "string2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Custom Font\n",
    "\n",
    "In OpenCV, only a subset of Hershey fonts are supported.  \n",
    "You can try **PIL.ImageFont** if you wanyt to use custom font.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import cv2\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "img1= cv2.imread('./images/messi5.jpg')\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2=img1.copy()\n",
    "img3=img1.copy()\n",
    "# img_can = np.zeros((200,600,3),np.uint8) # Make canvas and set the color black\n",
    "b,g,r,a = 0,255,255,0\n",
    "## Use cv2.FONT_HERSHEY_XXX to write English.\n",
    "text = time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime()) \n",
    "# cv2.putText(img1,  text, (10,50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (b,g,r), 1, cv2.LINE_AA)\n",
    "# cv2.putText(img2,  text, (10,50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (b,g,r), 1, cv2.LINE_AA)\n",
    "\n",
    "## Use custom font for Korean and Chinese.\n",
    "fontpath1 = \"./fonts/Gyeonggi_win_title_Bold.ttf\" # Korean\n",
    "fontpath2 = \"./fonts/SourceHanSerifSC-Bold.ttf\"   # Korean + Chinese  \n",
    "fontpath3 = \"./fonts/ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ˆìœ ë¯¼ê²½ì²´.ttf\"        # Korean Handwriting\n",
    "\n",
    "font1 = ImageFont.truetype(fontpath1, 32)\n",
    "font2 = ImageFont.truetype(fontpath2, 32)\n",
    "font3 = ImageFont.truetype(fontpath3, 48)\n",
    "\n",
    "img_pil1 = Image.fromarray(img1)\n",
    "img_pil2 = Image.fromarray(img2)\n",
    "img_pil3 = Image.fromarray(img3)\n",
    "\n",
    "draw1 = ImageDraw.Draw(img_pil1)\n",
    "draw2 = ImageDraw.Draw(img_pil2)\n",
    "draw3 = ImageDraw.Draw(img_pil3)\n",
    "draw1.text((10, 200),  \"í•œê¸€ í…ìŠ¤íŠ¸ ì¶”ê°€!\", font = font1, fill = (b, g, r, a))\n",
    "draw2.text((10, 300),  \"ë°•ìž¥ê²½, æœ´æ¼³ç‚…,\", font = font2, fill = (b, g, r, a))\n",
    "draw3.text((50,150),  \"ë°•ìž¥ê²½ PJK Handwriting\", font = font3, fill = (b, g, r, a))\n",
    "\n",
    "img1 = np.array(img_pil1)\n",
    "img2 = np.array(img_pil2)\n",
    "img3 = np.array(img_pil3)\n",
    "\n",
    "## Display \n",
    "# cv2.imshow(\"res\", img);cv2.waitKey();cv2.destroyAllWindows()\n",
    "# cv2.imwrite(\"res.png\", img)\n",
    "\n",
    "\n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "plt.subplot(131),plt.imshow(img1),plt.title('Korean'),plt.axis('off')\n",
    "plt.subplot(132),plt.imshow(img2),plt.title('Chinese'),plt.axis('off')\n",
    "plt.subplot(133),plt.imshow(img3),plt.title('Handwriting'),plt.axis('off')\n",
    "# plt.subplot(133),plt.imshow(cv2.cvtColor(fliped2, cv2.COLOR_BGR2RGB)),plt.title('remap flip'),plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Draw Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np  \n",
    "import cv2 \n",
    "\n",
    "markers = [\n",
    "    \"cv2.MARKER_CROSS\",\n",
    "    \"cv2.MARKER_TILTED_CROSS\",\n",
    "    \"cv2.MARKER_STAR\",\n",
    "    \"cv2.MARKER_DIAMOND\",\n",
    "    \"cv2.MARKER_SQUARE\",\n",
    "    \"cv2.MARKER_TRIANGLE_UP\",\n",
    "    \"cv2.MARKER_TRIANGLE_DOWN\",\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8), facecolor=\"w\")\n",
    "\n",
    "for i, marker in enumerate(markers, 1):\n",
    "    img = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "    cv2.drawMarker(img, (50, 50), color=(255, 0, 0), markerType=eval(marker), thickness=2)\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, i)\n",
    "    ax.set_title(marker)\n",
    "    ax.imshow(img)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# font = cv2.FONT_HERSHEY_COMPLEX | cv2.FONT_ITALIC\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "img = cv2.imread('./images/son/son4.jpg', -1) \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "markers = [\n",
    "    \"cv2.MARKER_CROSS\",\n",
    "    \"cv2.MARKER_TILTED_CROSS\",\n",
    "    \"cv2.MARKER_STAR\",\n",
    "    \"cv2.MARKER_DIAMOND\",\n",
    "    \"cv2.MARKER_SQUARE\",\n",
    "    \"cv2.MARKER_TRIANGLE_UP\",\n",
    "    \"cv2.MARKER_TRIANGLE_DOWN\",\n",
    "]\n",
    "cv2.putText(img,'copyright' ,(120,100), font, 2,(255,255,255),1)  \n",
    "cv2.drawMarker(img, (150, 50), color=(255, 0, 0), markerType=0, thickness=2)\n",
    "\n",
    "#Display the image  \n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–£ Dealing with Images\n",
    "In this section,we are going to discuss some of the basic operations that we can do on the images once we have successfully read them.  \n",
    "The operations we are going to do here:\n",
    "\n",
    "- Access pixel values and modify them\n",
    "- Access image properties\n",
    "- Set a Region of Interest (ROI)\n",
    "- Split and merge image channels\n",
    "\n",
    "## â–¶ Access pixel values and modify them  \n",
    "\n",
    "Pixel access is used to get or change values for specific coordinates in an array of images.  \n",
    "It is the same as the element approach in a numpy array, and you can change or assign values directly.  \n",
    "- You can access a pixel value by its row and column coordinates.   \n",
    "- For BGR image, it returns an array of Blue, Green, Red values.   \n",
    "- For grayscale image, just corresponding intensity is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "img = cv.imread('../images/dogs/04.jpg')\n",
    "px = img[100,100]\n",
    "print(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as you can see we got a list containing 3 values.  \n",
    "As we know OpenCV stores the color image as BGR color image,so the first value in the list is the value of the blue channel of this particular pixel, and the rest are values for green and red channels.  \n",
    "We can also access only one of the channels as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing only blue pixel\n",
    "blue = img[100,100,0]\n",
    "print( blue )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To modify the values, we just need to access the pixel and then overwrite it with a value as shown below:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[100:110,100:110] = [255,255,0] # yellow\n",
    "print(img[100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method to access and modify the pixel values is slow so you should make use of NumPy library as it is  optimized for fast array calculations.   \n",
    "For accessing individual pixel values, the Numpy array methods, array.item() and array.itemset() are considered better as they always return a scalar.   \n",
    "However, if you want to access all the B,G,R values, you will need to call array.  \n",
    "item() separately for each value as shown below:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../images/dogs/04.jpg')\n",
    "img.item(80,80,2)   # accessing RED channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.itemset((80,80,2),255) # modifying RED channel value\n",
    "img.item(80,80,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better pixel accessing and editing method :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing RED value\n",
    "img.item(10,10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying RED value\n",
    "img.itemset((10,10,2),100)\n",
    "img.item(10,10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access Pixel Value  PT\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "gray = np.linspace(0, 255, num=90000, endpoint=True, retstep=False, dtype=np.uint8).reshape(300, 300, 1) # 300Ã—300Ã—1, equal step\n",
    "color = np.zeros((300, 300, 3), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(color)\n",
    "# plt.imshow(gray, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color[0:150, :, 0] = gray[0:150, :, 0]  # Assign a value of gray to rows 0 ~ 150 of the Blue channel, which is a gradient image.\n",
    "plt.imshow(cv2.cvtColor(color, cv2.COLOR_BGR2RGB)),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color[:, 150:300, 2] = gray[:, 150:300, 0] # Assign a value of gray to rows 0 ~ 150 of the Red channel, which is a gradient image.\n",
    "plt.imshow(cv2.cvtColor(color, cv2.COLOR_BGR2RGB)),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, c = 200, 100, 0\n",
    "access_gray = gray[y, x, c]  # row(y) and column(x)\n",
    "access_color_blue = color[y, x, c]\n",
    "access_color = color[y, x]\n",
    "\n",
    "# print(access_gray)\n",
    "# print(access_color_blue)\n",
    "# print(access_color)\n",
    "\n",
    "cv2.imshow(\"gray\", gray)\n",
    "cv2.imshow(\"color\", color)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8,8))\n",
    "axs[0].imshow(gray,cmap='gray'), axs[0].axis('off'), axs[0].set_title('gray')\n",
    "axs[1].imshow(cv2.cvtColor(color, cv2.COLOR_BGR2RGB)), axs[1].axis('off'), axs[1].set_title('color')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Access Image properties  \n",
    "\n",
    "Often it is important to know the Image properties: \n",
    "- Image properties include number of rows, columns and channels, type of image data, number of pixels etc.  \n",
    "- The shape of an image is accessed by img.shape.   \n",
    "- It returns a tuple of number of rows, columns, and channels (if image is color):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/messi5.jpg')\n",
    "print(img.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of pixels is accessed by img.size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image datatype is obtained by `img.dtype`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.dtype )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Image ROI(Region of interest)\n",
    "\n",
    "Often you may come across some images where you are only interested in a specific region.   \n",
    "- Say you want to detect eyes in an image, will you search the entire image, possibly not as that may not fetch accurate results.   \n",
    "- But we know that eyes are a part of face, so it is better to detect a face first ,thus here the face is our ROI.   \n",
    "\n",
    "You may want to have a look at the article Face detection using Viola-Jones algorithm where we detect the faces and then find eyes in the area we found faces.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./images/park.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(img), plt.title('Park')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=310; y=120; w=50; h=50        # roi coordinate\n",
    "roi = img[y:y+h, x:x+w]         # roi       \n",
    "\n",
    "print(roi.shape)                # roi shape, (50,50,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(roi, (0,0), (h, w), (0,255,0),3) # draw rectangle \n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(img), plt.title('Park')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Slicing ROI\n",
    "\n",
    "When you execute the cv2.imread() function, it returns the image as a numpy array. numpy arrays can be sliced.   \n",
    "To specify the desired area, you can slice an array of images numpy.   \n",
    "In the above code, img[y:y+h, x:x+w] slices the desired area.  \n",
    "In other words, the ROI variable contains a numpy array that slices the statue that is the region of interest.  \n",
    "\n",
    "**cv2.rectangle(roi, (0,0), (h, w), (0,255,0))**\n",
    "\n",
    ">- (0, 0) left top of rectangle , (h, w) right btm: draw rectangle on roi    \n",
    ">- RGB (0, 255, 0) green "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi_copy\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img2 = cv2.imread('./images/park.jpg')\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "x=310; y=120; w=50; h=50\n",
    "roi = img2[y:y+h, x:x+w]     # roi \n",
    "img2_roi = roi.copy()           \n",
    "\n",
    "img2[y:y+h, x+w:x+w+w] = roi  # new psn\n",
    "# cv2.rectangle(img2, (x,y), (x+w+w, y+h), (255,255,0),4) # draw rectangle \n",
    "\n",
    "cv2.imshow(\"Orig with ROI\", img)      \n",
    "cv2.imshow(\"Copied ROI\", img2)      \n",
    "cv2.imshow(\"roi\", img2_roi)     \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "fig, axs = plt.subplots(1,3,figsize=(15,10))\n",
    "axs[0].imshow(img), axs[0].axis('off'), axs[0].set_title('Park with ROI Image')\n",
    "axs[1].imshow(img2), axs[1].axis('off'), axs[1].set_title('2 Statues')\n",
    "axs[2].imshow(img2_roi), axs[2].axis('off'), axs[2].set_title('Sliced ROI Img')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROI is again obtained using Numpy indexing. Here I am selecting the ball and copying it to another region in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_messi = cv2.imread('./images/messi5.jpg')\n",
    "img_messi = cv2.cvtColor(img_messi, cv2.COLOR_BGR2RGB)\n",
    "ball = img_messi[280:340, 330:390]\n",
    "img_messi[273:333, 100:160] = ball\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(img_messi), plt.title('2 Balls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Drag the mouse to mark the ROI \n",
    "\n",
    "In order to mark a region of interest, you need the coordinates and size (height, width) of the desired area.   \n",
    "However, it is a hassle to enter this number every time.   \n",
    "It would be more convenient if you dragged the area of interest with the mouse to display it, right?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi_crop_mouse\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "isDragging = False                      # mouse drag\n",
    "x0, y0, w, h = -1,-1,-1,-1              # roi coord\n",
    "blue, red = (255,0,0),(0,0,255)         # color\n",
    "\n",
    "def onMouse(event,x,y,flags,param):     # mouse event handle function  \n",
    "    global isDragging, x0, y0, img      # global var\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # LBUTTONDOWN \n",
    "        isDragging = True               # and drag\n",
    "        x0 = x\n",
    "        y0 = y\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:  # MOUSEMOVE\n",
    "        if isDragging:                  \n",
    "            img_draw = img.copy()       \n",
    "            cv2.rectangle(img_draw, (x0, y0), (x, y), blue, 2) # dragging area\n",
    "            cv2.imshow('img', img_draw) \n",
    "    elif event == cv2.EVENT_LBUTTONUP:  # LBUTTONUP\n",
    "        if isDragging:                  # drag stop\n",
    "            isDragging = False          \n",
    "            w = x - x0                  # dragging width\n",
    "            h = y - y0                  # dragging height\n",
    "            print(\"x:%d, y:%d, w:%d, h:%d\" % (x0, y0, w, h))\n",
    "            if w > 0 and h > 0:         \n",
    "                img_draw = img.copy()   \n",
    "                cv2.rectangle(img_draw, (x0, y0), (x, y), red, 2)  \n",
    "#                 cv2.imshow('img_draw1', img_draw) \n",
    "                roi = img[y0:y0+h, x0:x0+w] # ROI\n",
    "                img[280:280+h, 100:100+w] = roi \n",
    "                cv2.imshow('roi', roi)  \n",
    "                cv2.imshow('img', img)  \n",
    "                cv2.moveWindow('roi2 cropped', 50, 100) \n",
    "#                 cv2.imwrite('./results/cropped.jpg', roi)   \n",
    "                print(\"croped.\")\n",
    "            else:\n",
    "                cv2.imshow('img', img)  \n",
    "                print(\"Please Drag the area from the top left to the bottom right.\")\n",
    "\n",
    "img = cv2.imread('./images/messi5.jpg')\n",
    "img_org = img.copy()\n",
    "cv2.imshow('img', img)\n",
    "cv2.setMouseCallback('img', onMouse) \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "plt.subplot(121),plt.imshow(cv2.cvtColor(img_org, cv2.COLOR_BGR2RGB)),plt.title('original'),plt.axis('off')\n",
    "# plt.subplot(132),plt.imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)),plt.title('ROI'),plt.axis('off')\n",
    "plt.subplot(122),plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)),plt.title('double img'),plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, there is a code cv2.imshow('cropped', roi) that opens the area of interest in a new window, but there is no code to open the original image.   \n",
    "However, when you run the code, the original image also appears.   \n",
    "When you call the cv2.selectROI() function, the original image will appear, and it will also help you handle mouse events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi_select_img.py\n",
    "import cv2, numpy as np\n",
    "\n",
    "img = cv2.imread('./images/park.jpg')\n",
    "img1 = img.copy()\n",
    "x,y,w,h= cv2.selectROI('img', img, False)\n",
    "if w and h:\n",
    "    roi = img[y:y+h, x:x+w]\n",
    "    cv2.imshow('cropped', roi)  \n",
    "    cv2.moveWindow('cropped', 10, 50) \n",
    "    cv2.imwrite('.result/cropped2.jpg', roi)   \n",
    "    \n",
    "img[y:y+h, x+w:x+w+w] = roi # double the img on org img  \n",
    "cv2.imshow('double', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "plt.subplot(131),plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)),plt.title('original'),plt.axis('off')\n",
    "plt.subplot(132),plt.imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)),plt.title('ROI'),plt.axis('off')\n",
    "plt.subplot(133),plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)),plt.title('double img'),plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Splitting and Merging Image Channels\n",
    "We can also split the channels from an image and then work on each channel separately.   \n",
    "Or sometimes you may need to merge them back together, here is how we do it:\n",
    "\n",
    "But this method is painfully slow, so we can also use the Numpy to do the same, here is how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('./images/ex01.jpg')\n",
    "\n",
    "b,g,r = cv.split(img)\n",
    "img = cv.merge((b,g,r))\n",
    "b = img[:,:,0]\n",
    "g = img[:,:,1]\n",
    "r = img[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3,figsize=(5,5))\n",
    "axs[0].imshow(b), axs[0].axis('off'), axs[0].set_title('Blue')\n",
    "axs[1].imshow(g), axs[1].axis('off'), axs[1].set_title('Green')\n",
    "axs[2].imshow(r), axs[2].axis('off'), axs[2].set_title('Red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose you want to just set all the values in the red channel to zero, here is how to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sets all values in red channel as zero\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sets all values in red channel as zero\n",
    "img[:,:,2] = 0\n",
    "b,g,r = cv.split(img)\n",
    "bgz = cv2.merge((b, g, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3,figsize=(5,5))\n",
    "axs[0].imshow(b), axs[0].axis('off'), axs[0].set_title('Blue')\n",
    "axs[1].imshow(g), axs[1].axis('off'), axs[1].set_title('Green')\n",
    "axs[2].imshow(bgz), axs[2].axis('off'), axs[2].set_title('Red=0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "height, width, channel = img.shape\n",
    "zero = np.zeros((height, width, 1), dtype=np.uint8)\n",
    "bgz = cv2.merge((b, g, zero))\n",
    "bzr = cv2.merge((b, zero, r))\n",
    "zgr = cv2.merge((zero, g, r))\n",
    "\n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "plt.subplot(131),plt.imshow(bgz),plt.title('Red=0'),plt.axis('off')\n",
    "plt.subplot(132),plt.imshow(bzr),plt.title('Green=0'),plt.axis('off')\n",
    "plt.subplot(133),plt.imshow(zgr),plt.title('Blue=0'),plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Making Borders for Images (Padding)\n",
    "If you want to create a border around the image, something like a photo frame,   \n",
    "you can use cv.copyMakeBorder().   \n",
    "But it has more applications for convolution operation, zero padding etc.   \n",
    "This function takes following arguments:\n",
    "~ Syntax:  \n",
    "    \n",
    "- **cv.copyMakeBorder(src, top, bottom, left, right, borderType, None, value)**  \n",
    "\n",
    "~ Parameters:  \n",
    "    \n",
    ">- src - input image\n",
    ">- top, bottom, left, right - border width in number of pixels in corresponding directions\n",
    ">- borderType - Flag defining what kind of border to be added. It can be following types:\n",
    ">>- cv.BORDER_CONSTANT - Adds a constant colored border. The value should be given as next argument.\n",
    ">>- cv.BORDER_REFLECT - Border will be mirror reflection of the border elements, like this : fedcba|abcdefgh|hgfedcb\n",
    ">>- cv.BORDER_REFLECT_101 or cv.BORDER_DEFAULT - Same as above, but with a slight change, like this : gfedcb|abcdefgh|gfedcba\n",
    ">>- cv.BORDER_REPLICATE - Last element is replicated throughout, like this: aaaaaa|abcdefgh|hhhhhhh\n",
    ">>- cv.BORDER_WRAP - Can't explain, it will look like this : cdefgh|abcdefgh|abcdefg\n",
    ">- value - Color of border if border type is cv.BORDER_CONSTANT  \n",
    "\n",
    "Below is a sample code demonstrating all these border types for better understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "from random import randint\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "# BLUE = [255,0,0]\n",
    "value = [randint(0, 255), randint(0, 255), randint(0, 255)]\n",
    "\n",
    "img1 = cv2.imread('./images/opencv-logo.png')\n",
    "top = int(0.05 * img1.shape[0]) # shape[0] = rows\n",
    "bottom = top\n",
    "left = int(0.05 * img1.shape[1]) # shape[1] = cols\n",
    "right = left\n",
    "replicate = cv2.copyMakeBorder(img1,top, bottom, left, right,cv2.BORDER_REPLICATE,None,value)\n",
    "reflect = cv2.copyMakeBorder(img1,top, bottom, left, right,cv2.BORDER_REFLECT,None,value)\n",
    "reflect101 = cv2.copyMakeBorder(img1,top, bottom, left, right,cv2.BORDER_REFLECT_101,None,value)\n",
    "wrap = cv2.copyMakeBorder(img1,top, bottom, left, right,cv2.BORDER_WRAP,None,value)\n",
    "constant= cv2.copyMakeBorder(img1,top, bottom, left, right,cv2.BORDER_CONSTANT,None,value)\n",
    "plt.subplot(231),plt.imshow(img1,'gray'),plt.title('ORIGINAL')\n",
    "plt.subplot(232),plt.imshow(replicate,'gray'),plt.title('REPLICATE')\n",
    "plt.subplot(233),plt.imshow(reflect,'gray'),plt.title('REFLECT')\n",
    "plt.subplot(234),plt.imshow(reflect101,'gray'),plt.title('REFLECT_101')\n",
    "plt.subplot(235),plt.imshow(wrap,'gray'),plt.title('WRAP')\n",
    "plt.subplot(236),plt.imshow(constant,'gray'),plt.title('CONSTANT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Keys\n",
    "\n",
    "Command Mode\n",
    "- add cell above : a\n",
    "- add cell below : b\n",
    "- delete cell : dd    \n",
    "- run cell : shift + enter (cursor move to next cell)     \n",
    "- run cell : shift + enter (cursor stay current cell)\n",
    "- merge cell : shift + 'm' \n",
    "- change cmd mode (markdown) to edit mode : 'y'      \n",
    "- change edit mode to markdown exec : esc and 'm'    \n",
    "\n",
    "## Short Keys\n",
    "\n",
    "Edit Mode  \n",
    "- split cell : ctrl + shift + '-'\n",
    "- multiple exec(change/copy/del) at one time : move cursor to the point and click with ctrl  \n",
    "- del line : ctrl + 'x'\n",
    "- copy line : ctrl + 'c'\n",
    "- paste line : ctrl + 'v'\n",
    "- code line to comment line (toggle) : ctrl + '/'\n",
    "    \n",
    "## Others\n",
    "\n",
    "- Markdown Emojis : window + '.'\n",
    "> https://github.com/markdown-templates/markdown-emojis  \n",
    "\n",
    "- Latex Eq\n",
    "> https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:TeX_%EB%AC%B8%EB%B2%95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assgn 02"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
